{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the Face Recognition Model from FaceNet\n",
    "\n",
    "I will be using stochastic gradient descent, which deviates from the use of mini-batch gradient descent in the FaceNet paper. For each epoch, I will be creating a list of (Anchor,Pos ex., Neg ex.) pairs which corresponds to all anchor positive pairs and the selection of semi-hard negatives based on encoding vector distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import latex\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426,)\n",
      "(426, 220, 220, 3)\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "names = np.load(\"../../data/facenet/names.npy\")\n",
    "images = np.load(\"../../data/facenet/images.npy\")\n",
    "print(names.shape)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Parameters\n",
    "\n",
    "Note - there are three outputs from the placeholder function corresponding to a placeholder for an anchor image, a positive image, and a negative image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder values for input image data\n",
    "def get_placeholders(x_h,x_w,x_c):\n",
    "    \"\"\"\n",
    "    x_h: Height for image input \n",
    "    x_w: Width for image input\n",
    "    x_c: Channels for image input\n",
    "    \"\"\"\n",
    "    anchor = tf.placeholder(tf.float32, name=\"anchor\", shape=(None,x_h,x_w,x_c))\n",
    "    pos = tf.placeholder(tf.float32, name=\"pos_ex\", shape=(None,x_h,x_w,x_c))\n",
    "    neg = tf.placeholder(tf.float32, name=\"neg_ex\", shape=(None,x_h,x_w,x_c))\n",
    "    return [anchor,pos,neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor shape: (?, 220, 220, 3)\n",
      "Pos. example shape: (?, 220, 220, 3)\n",
      "Neg. example shape: (?, 220, 220, 3)\n"
     ]
    }
   ],
   "source": [
    "# Testing placeholders function\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    anch,pos,neg = get_placeholders(220,220,3)\n",
    "    print(\"Anchor shape:\",anch.shape)\n",
    "    print(\"Pos. example shape:\",pos.shape)\n",
    "    print(\"Neg. example shape:\",neg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow forward prop\n",
    "\n",
    "Using the NN1 architecture outlined in the FaceNet paper. Note - I adjust this model slightly, in that I add batch normalization during the convolution steps to increase training time and simultaneously handle regularization concerns. I also slightly alter the fully-connected layers steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(input_images):\n",
    "    img1,img2,img3 = input_images\n",
    "    img_enc1 = conv_network(img1)\n",
    "    img_enc2 = conv_network(img2)\n",
    "    img_enc3 = conv_network(img3)\n",
    "    return [img_enc1,img_enc2,img_enc3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constant layer for 2d convolution, batch norm, and activation\n",
    "def conv(the_input,layer,f,ks,s):\n",
    "    \"\"\"\n",
    "    the_input: the layer which will be used as input in conv layer\n",
    "    layer: specifies the layer number for naming sections of graph\n",
    "    f (filters): the number of filters to be used for conv layer\n",
    "    ks (kernel_size): kernel size for conv2d layer\n",
    "    s: stride for conv2d layer\n",
    "    \"\"\"\n",
    "    layer = str(layer)\n",
    "    Z = tf.layers.conv2d(the_input,filters=f,kernel_size=[ks,ks],strides=(s,s),padding=\"same\",name=\"Z\"+layer,kernel_initializer=tf.contrib.layers.xavier_initializer(seed=0),reuse=tf.AUTO_REUSE)\n",
    "    Bn = tf.layers.batch_normalization(Z,name=\"Bn\"+layer,reuse=tf.AUTO_REUSE)\n",
    "    A = tf.nn.relu(Bn,name=\"A\"+layer)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN1 architecture outlined in FaceNet paper with slight adjustments\n",
    "def conv_network(X):\n",
    "    input_layer = tf.reshape(X,[-1,220,220,3]) # Input shape of images\n",
    "    S1 = conv(input_layer,1,64,7,2) # 110x110x64 \n",
    "    P1 = tf.layers.max_pooling2d(S1,pool_size=[3,3],strides=2,padding=\"same\",name=\"P1\")\n",
    "    S2 = conv(P1,2,64,1,1)\n",
    "    S3 = conv(S2,3,192,3,1)\n",
    "    P3 = tf.layers.max_pooling2d(S3,pool_size=[3,3],strides=2,padding=\"same\",name=\"P3\")\n",
    "    S4 = conv(P3,4,192,1,1)\n",
    "    S5 = conv(S4,5,384,3,1)\n",
    "    P5 = tf.layers.max_pooling2d(S5,pool_size=[3,3],strides=2,padding=\"same\",name=\"P5\")\n",
    "    S6 = conv(P5,6,384,1,1)\n",
    "    S7 = conv(S6,7,256,3,1)\n",
    "    S8 = conv(S7,8,256,1,1)\n",
    "    S9 = conv(S8,9,256,3,1)\n",
    "    S10 = conv(S9,10,256,1,1)\n",
    "    S11 = conv(S10,11,256,3,1)\n",
    "    P11 = tf.layers.max_pooling2d(S11,pool_size=[3,3],strides=2,padding=\"same\",name=\"P11\")\n",
    "    # Reshape and maxout,fully connected layers\n",
    "    Mo1 = tf.contrib.layers.maxout(P11,128) # 7x7x128\n",
    "    F = tf.layers.flatten(Mo1,name=\"Flatten\")\n",
    "    Fc1 = tf.layers.dense(F,4096,activation=tf.nn.relu,name=\"Fc1\",reuse=tf.AUTO_REUSE)\n",
    "    Do = tf.layers.dropout(Fc1,rate=0.2,name=\"Dropout\")\n",
    "    Fc2 = tf.layers.dense(Do,128,activation=None,name=\"Fc2\",reuse=tf.AUTO_REUSE)\n",
    "    return Fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor embedding shape: (1, 128)\n",
      "Positive embedding shape: (1, 128)\n",
      "Negative embedding shape: (1, 128)\n"
     ]
    }
   ],
   "source": [
    "# Testing forward prop\n",
    "tf.reset_default_graph()\n",
    "img1,img2,img3 = images[0],images[1],images[2]\n",
    "img1.shape = (1,220,220,3)\n",
    "img2.shape = (1,220,220,3)\n",
    "img3.shape = (1,220,220,3)\n",
    "with tf.Session() as sess:\n",
    "    aimg1,aimg2,aimg3 = get_placeholders(220,220,3)\n",
    "    embeddings = forward_pass([aimg1,aimg2,aimg3])\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    aembedding = sess.run(embeddings,feed_dict={aimg1:img1,aimg2:img2,aimg3:img3})\n",
    "    print(\"Anchor embedding shape:\", str(aembedding[0].shape))\n",
    "    print(\"Positive embedding shape:\", str(aembedding[1].shape))\n",
    "    print(\"Negative embedding shape:\", str(aembedding[2].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Triplet Loss\n",
    "\n",
    "$$ J = \\sum_{i=1}^{m} \\bigg[ || f(x_i^a) - f(x^p_i) ||_2^2 - || f(x_i^a) - f(x^n_i) ||_2^2 + \\alpha \\bigg] $$\n",
    "Note - I am not normalizing encoding vectors.\n",
    "\n",
    "Terms:\n",
    "- alpha: margin (set to 0.2 here)\n",
    "- x<sub>i</sub><sup>a</sup>: anchor encoding\n",
    "- x<sub>i</sub><sup>p</sup>: positive example encoding\n",
    "- x<sub>i</sub><sup>n</sup>: negative example encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input embeddings is a list of three (None,128) embeddings\n",
    "def cost_function(embeddings,alpha=0.2):\n",
    "    anchor,pos,neg = embeddings\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,pos)))\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,neg)))\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist,neg_dist),alpha)\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss,0.0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 0.0\n",
      "cost shape: ()\n"
     ]
    }
   ],
   "source": [
    "# Testing cost function\n",
    "tf.reset_default_graph()\n",
    "img1,img2,img3 = images[0],images[1],images[2]\n",
    "img1.shape,img2.shape,img3.shape = (1,220,220,3),(1,220,220,3),(1,220,220,3)\n",
    "with tf.Session() as sess:\n",
    "    aimg1,aimg2,aimg3 = get_placeholders(220,220,3)\n",
    "    embeddings = forward_pass([aimg1,aimg2,aimg3])\n",
    "    cost = cost_function(embeddings) \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    acost = sess.run(cost,feed_dict={aimg1:img1,aimg2:img2,aimg3:img3})\n",
    "    print(\"cost:\",acost)\n",
    "    print(\"cost shape:\",cost.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
