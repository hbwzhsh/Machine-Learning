{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow implementation of googLeNet \n",
    "\n",
    "This specific model is outlined in \"Going deeper with convolutions\", authored by Christian Szegedy, Wei Liu, among others. I will be using this model to handle a simple image recognition task, with the intention of the notebook to create a low bias model with a smaller number of parameters than a traditional convnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import latex\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting images and their labels\n",
    "path = \"../../data/Sign-Language-Digits-Dataset/Dataset/\"\n",
    "imgs = []\n",
    "encodings = []\n",
    "for folder in os.listdir(path):\n",
    "    if folder[0] != \".\":\n",
    "        name = folder\n",
    "        for image in os.listdir(path+folder):\n",
    "            if \".JPG\" in image:\n",
    "                aimg = cv2.imread(path+folder+\"/\"+image,1)\n",
    "                if aimg.shape == (100,100,3):\n",
    "                    imgs.append(aimg)\n",
    "                    encodings.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing numbered labels\n",
    "final_encodings = []\n",
    "for encoding in encodings:\n",
    "    enc_num = int(encoding)\n",
    "    enc_swp = np.zeros((10,))\n",
    "    enc_swp[enc_num] = 1\n",
    "    final_encodings.append(enc_swp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2059, 100, 100, 3)\n",
      "(2059, 10)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(imgs)\n",
    "y = np.array(final_encodings)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../../data/signs_data/X.npy\",X)\n",
    "np.save(\"../../data/signs_data/y.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2059, 100, 100, 3)\n",
      "(2059, 10)\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint\n",
    "X = np.load(\"../../data/signs_data/X.npy\")\n",
    "y = np.load(\"../../data/signs_data/y.npy\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This particular model uses encodings of shape (224,224,3) so reshaping input \n",
    "resized_imgs = []\n",
    "for i in range(X.shape[0]):\n",
    "    r_img = cv2.resize(X[i], (224, 224))\n",
    "    resized_imgs.append(r_img)\n",
    "print(len(resized_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(resized_imgs)\n",
    "encodings = y\n",
    "print(images.shape)\n",
    "print(encodings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0])\n",
    "plt.show()\n",
    "print(\"encoding:\",encodings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder values for input X,y data\n",
    "def get_placeholders(x_h,x_w,x_c,y_c):\n",
    "    \"\"\"\n",
    "    x_h: Height for x input \n",
    "    x_w: Width for x input\n",
    "    x_c: Channels for x input\n",
    "    y_c: Channels for y input\n",
    "    \"\"\"\n",
    "    X = tf.placeholder(tf.float32, name=\"X\", shape=(None,x_h,x_w,x_c))\n",
    "    y = tf.placeholder(tf.float32, name=\"y\", shape=(None,y_c))\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing placeholders\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    X,y = get_placeholders(224,224,3,10)\n",
    "    print(\"X shape:\",X.shape)\n",
    "    print(\"y shape:\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Forward Propagation\n",
    "\n",
    "Within the inception block, the filters input describes the number of filters used for both the bottleneck conv layers and the nxn conv layers and is as follows: [1x1 conv [f1], 1x1 conv(bottleneck) [f2], 3x3 conv [f3], 1x1 conv(bottleneck) [f4], 5x5 conv [f5], 1x1 conv(bottleneck for maxpool) [f6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponds with two softmax outputs before the final softmax output at the end of the model\n",
    "# Input of shape 14x14xchannels\n",
    "def early_softmax(the_input,stage,f):\n",
    "    \"\"\"\n",
    "    stage: a,b depending on which softmax stage\n",
    "    \"\"\"\n",
    "    Avg = tf.layers.average_pooling2d(the_input,pool_size=[5,5],strides=3,padding=\"valid\",name=\"AP\"+stage) # 4x4xC\n",
    "    Conv = tf.layers.conv2d(Avg,filters=f,kernel_size=[1,1],strides=(1,1),padding=\"same\",name=\"Conv\"+stage,kernel_initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    Conv_A = tf.nn.relu(Conv,name=\"Conv_A\"+stage)\n",
    "    Flat_A = tf.layers.flatten(Conv_A,name=\"Flatten_\"+stage)\n",
    "    Dense_1 = tf.layers.dense(Flat_A,1024,activation=tf.nn.relu,name=\"Fc1_\"+stage)\n",
    "    Drop_1 = tf.layers.dropout(Dense_1,rate=0.4,name=\"Drop1_\"+stage)\n",
    "    Dense_2 = tf.layers.dense(Drop_1,f,activation=tf.nn.relu,name=\"Fc2_\"+stage)\n",
    "    Drop_2 = tf.layers.dropout(Dense_2,rate=0.4,name=\"Drop2_\"+stage)\n",
    "    linear = tf.layers.dense(Drop_2,10,activation=None,name=\"linear_\"+stage)\n",
    "    return linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponds with a inception block, including depth concatenation\n",
    "# s: number of the inception stage, blocks within a stage are labled alphabetically\n",
    "def inception_step(the_input,filters,s):\n",
    "    f1,f2,f3,f4,f5,f6 = filters\n",
    "    s = str(s)\n",
    "    # Block 1:\n",
    "    Z1 = tf.layers.conv2d(the_input,filters=f1,kernel_size=[1,1],strides=(1,1),padding=\"same\",name=\"Z1_\"+s,kernel_initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    A1 = tf.nn.relu(Z1,name=\"A1_\"+s)\n",
    "    # Block 2:\n",
    "    # 3x3 bottleneck\n",
    "    Z2a = tf.layers.conv2d(the_input,filters=f2,kernel_size=[1,1],strides=(1,1),padding=\"same\",name=\"Z2a_\"+s,kernel_initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    A2a = tf.nn.relu(Z2a,name=\"A2a_\"+s)\n",
    "    # 3x3 conv\n",
    "    Z2b = tf.layers.conv2d(A2a,filters=f3,kernel_size=[3,3],strides=(1,1),padding=\"same\",name=\"Z2b_\"+s,kernel_initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    A2b = tf.nn.relu(Z2b,name=\"A2b_\"+s)\n",
    "    # Block 3:\n",
    "    # 5x5 bottleneck\n",
    "    Z3a = tf.layers.conv2d(the_input,filters=f4,kernel_size=[1,1],strides=(1,1),padding=\"same\",name=\"Z3a_\"+s,kernel_initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    A3a = tf.nn.relu(Z3a,name=\"A3a_\"+s)\n",
    "    # 5x5 conv\n",
    "    Z3b = tf.layers.conv2d(A3a,filters=f5,kernel_size=[5,5],strides=(1,1),padding=\"same\",name=\"Z3b_\"+s,kernel_initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    A3b = tf.nn.relu(Z3b,name=\"A3b_\"+s)\n",
    "    # Block 4\n",
    "    P4 = tf.layers.max_pooling2d(the_input,pool_size=[3,3],strides=1,padding=\"same\",name=\"P4_\"+s)\n",
    "    Z4 = tf.layers.conv2d(P4,filters=f6,kernel_size=[1,1],strides=(1,1),padding=\"same\",name=\"Z4_\"+s,kernel_initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    A4 = tf.nn.relu(Z4,name=\"A4_\"+s)\n",
    "    # Concat all 4 blocks\n",
    "    Dc = tf.concat([A1,A2b,A3b,A4],axis=-1,name=\"concat_\"+s)\n",
    "    return Dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There will be three softmax outputs returned\n",
    "def forward_pass(X):\n",
    "    input_layer = tf.reshape(X,[-1,224,224,3]) # Input shape of images\n",
    "    # Pre-inception\n",
    "    Z1 = tf.layers.conv2d(input_layer,filters=64,kernel_size=[7,7],strides=(2,2),padding=\"same\",name=\"Z1\",kernel_initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    A1 = tf.nn.relu(Z1,name=\"A1\") # 112x112\n",
    "    P1 = tf.layers.max_pooling2d(A1,pool_size=[3,3],strides=2,padding=\"same\",name=\"P1\") # 56x56\n",
    "    LRN1 = tf.nn.local_response_normalization(P1,name=\"LRN1\")\n",
    "    Z2 = tf.layers.conv2d(LRN1,filters=64,kernel_size=[1,1],strides=(1,1),padding=\"valid\",name=\"Z2\",kernel_initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    A2 = tf.nn.relu(Z2,name=\"A2\")\n",
    "    Z3 = tf.layers.conv2d(A2,filters=192,kernel_size=[3,3],strides=(1,1),padding=\"same\",name=\"Z3\",kernel_initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    A3 = tf.nn.relu(Z3,name=\"A3\")\n",
    "    LRN3 = tf.nn.local_response_normalization(A3,name=\"LRN3\")\n",
    "    P3 = tf.layers.max_pooling2d(LRN3,pool_size=[3,3],strides=2,padding=\"same\",name=\"P3\") # 28x28x192\n",
    "    # Inception starts\n",
    "    Inc1 = inception_step(P3,[64,96,128,16,32,32],1) # 28x28x256\n",
    "    Inc2 = inception_step(Inc1,[128,128,192,32,96,64],2) #28x28x480\n",
    "    P4 = tf.layers.max_pooling2d(Inc2,pool_size=[3,3],strides=2,padding=\"same\",name=\"P4\") # 14x14x480\n",
    "    Inc3 = inception_step(P4,[192,96,208,16,48,64],3) #14x14x512\n",
    "    # First early softmax\n",
    "    ESM1 = early_softmax(Inc3,\"a\",512)\n",
    "    Inc4 = inception_step(Inc3,[160,112,224,24,64,64],4) # 14x14x512\n",
    "    Inc5 = inception_step(Inc4,[128,128,256,24,64,64],5) # 14x14x512\n",
    "    Inc6 = inception_step(Inc5,[112,144,288,32,64,64],6) # 14x14x528\n",
    "    # Second early softmax\n",
    "    ESM2 = early_softmax(Inc6,\"b\",528)\n",
    "    Inc7 = inception_step(Inc6,[256,160,320,32,128,128],7) # 14x14x832\n",
    "    P5 = tf.layers.max_pooling2d(Inc7,pool_size=[3,3],strides=2,padding=\"same\",name=\"P5\") # 7x7x832\n",
    "    Inc8 = inception_step(P5,[256,160,320,32,128,128],8) # 7x7x832\n",
    "    Inc9 = inception_step(Inc8,[384,192,384,48,128,128],9) # 7x7x1024\n",
    "    # Last softmax output\n",
    "    AP = tf.layers.average_pooling2d(Inc9,pool_size=[7,7],strides=1,padding=\"valid\",name=\"APc\") # 1x1x1024\n",
    "    Flat = tf.layers.flatten(AP,name=\"Flatten_c\")\n",
    "    Dense = tf.layers.dense(Flat,500,activation=tf.nn.relu,name=\"Fc1_c\")\n",
    "    Drop = tf.layers.dropout(Dense,rate=0.4,name=\"Drop1_c\")\n",
    "    ESM3 = tf.layers.dense(Drop,10,activation=None,name=\"linear_c\")\n",
    "    \n",
    "    return [ESM1,ESM2,ESM3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing forward prop step\n",
    "test_img = images[0]\n",
    "test_img.shape = (1,224,224,3)\n",
    "test_enc = encodings[0]\n",
    "test_enc.shape = (1,10)\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    X,y = get_placeholders(224,224,3,10)\n",
    "    Z = forward_pass(X)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    aZ = sess.run(Z,feed_dict={X:test_img,y:test_enc})\n",
    "    print(aZ[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Cost Function\n",
    "\n",
    "The cost function for this model is simple in that it is a simple softmax cross entropy loss. The only complexity related to this is the fact that there are three softmax outputs from the original model corresponding to predictions at different depths within the model. I plan on putting more weight on the softmax outputs from the deeper portions of the model rather than having there be an equal weighting: 0.4 for the last softmax output and 0.3 for the first two softmax outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a list of costs and the correct encoding and returns a weighted cost of the softmax predictions\n",
    "# Out3 corresponds with the last softmax prediction\n",
    "def cost_function(outputs,y):\n",
    "    out1,out2,out3 = outputs\n",
    "    cost_a = 0.3 * tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=out1,labels=y))\n",
    "    cost_b = 0.3 * tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=out2,labels=y))\n",
    "    cost_c = 0.4 * tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=out3,labels=y))\n",
    "    full_cost = cost_a + cost_b + cost_c\n",
    "    return full_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing cost function\n",
    "test_img = images[0]\n",
    "test_img.shape = (1,224,224,3)\n",
    "test_enc = encodings[0]\n",
    "test_enc.shape = (1,10)\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    X,y = get_placeholders(224,224,3,10)\n",
    "    Z = forward_pass(X)\n",
    "    cost = cost_function(Z,y)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    aCost = sess.run(cost,feed_dict={X:test_img,y:test_enc})\n",
    "    print(\"Cost:\",aCost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using stochastic gradient descent\n",
    "def model(images,encodings,lr=0.0001,num_epochs=5,print_cost=True):\n",
    "    tf.reset_default_graph() # resetting graph\n",
    "    tf.set_random_seed(1)\n",
    "    seed = 0\n",
    "    costs=[]\n",
    "    x_h = images[0].shape[0]\n",
    "    x_w = images[0].shape[1]\n",
    "    x_c = images[0].shape[2]\n",
    "    \n",
    "    X,y = get_placeholders(x_h,x_w,x_c,10) # 10 classes\n",
    "    Z = forward_pass(X)\n",
    "    cost = cost_function(Z,y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver() # to save/load model\n",
    "    with tf.Session() as sess:\n",
    "        # Loading saved model\n",
    "        # saver = tf.train.import_meta_graph(\"../../data/googlenet/inception_model.ckpt.meta\")\n",
    "        # saver.restore(sess, \"../../data/googlenet/inception_model.ckpt\")\n",
    "        sess.run(init) # DON'T RUN INIT IF LOADING MODEL\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            running_cost = 0\n",
    "            # shuffle data for each epoch\n",
    "            seed += 1\n",
    "            images = shuffle(images,random_state=seed)\n",
    "            encodings = shuffle(encodings,random_state=seed)\n",
    "            \n",
    "            for i in range(images.shape[0]):\n",
    "                a_img = images[i]\n",
    "                a_enc = encodings[i]\n",
    "                a_img.shape = (1,224,224,3)\n",
    "                a_enc.shape = (1,10)\n",
    "                _,temp_cost = sess.run([optimizer,cost], feed_dict={X:a_img,y:a_enc})\n",
    "                running_cost += temp_cost\n",
    "                # print(\"running cost: \"+str(running_cost) + \" ,temp_cost: \" + str(temp_cost)+\".\")\n",
    "                \n",
    "            costs.append(running_cost)\n",
    "            if print_cost and epoch % 1 == 0:\n",
    "                print(\"Cost at epoch {}: {}\".format(epoch+1,running_cost))\n",
    "                \n",
    "        loc = saver.save(sess, \"../../data/googlenet/inception_model.ckpt\")\n",
    "        return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acosts1 = model(images,encodings,lr=0.00001,num_epochs=15,print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iter = [i for i in range(15)]\n",
    "all_costs = acosts1\n",
    "plt.plot(x_iter,all_costs)\n",
    "plt.title(\"Cost vs epoch\")\n",
    "plt.xlabel(\"epoch #\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 1: 4228.0040545761585\n",
      "Cost at epoch 2: 2007.4463422904955\n",
      "Cost at epoch 3: 1242.6089914250133\n",
      "Cost at epoch 4: 834.4975922296275\n",
      "Cost at epoch 5: 614.461458436151\n",
      "Cost at epoch 6: 468.2891068336725\n",
      "Cost at epoch 7: 380.3431925270951\n",
      "Cost at epoch 8: 329.67680578217545\n"
     ]
    }
   ],
   "source": [
    "acosts1 = model(images,encodings,lr=0.00001,num_epochs=8,print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../data/googlenet/inception_model.ckpt\n",
      "Cost at epoch 1: 4737.832586288452\n",
      "Cost at epoch 2: 4729.91846871376\n",
      "Cost at epoch 3: 4700.812566041946\n",
      "Cost at epoch 4: 4566.428528666496\n",
      "Cost at epoch 5: 4152.427567362785\n",
      "Cost at epoch 6: 3676.3979907035828\n",
      "Cost at epoch 7: 3277.0295738875866\n",
      "Cost at epoch 8: 2953.4947279393673\n"
     ]
    }
   ],
   "source": [
    "acosts2 = model(images,encodings,lr=0.000001,num_epochs=8,print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../data/googlenet/inception_model.ckpt\n",
      "Cost at epoch 1: 2770.913605131209\n",
      "Cost at epoch 2: 2742.001461520791\n",
      "Cost at epoch 3: 2717.341639958322\n",
      "Cost at epoch 4: 2694.030679680407\n",
      "Cost at epoch 5: 2670.079291962087\n",
      "Cost at epoch 6: 2646.9252618551254\n",
      "Cost at epoch 7: 2625.2605364471674\n",
      "Cost at epoch 8: 2604.8839012756944\n"
     ]
    }
   ],
   "source": [
    "acosts3 = model(images,encodings,lr=0.0000001,num_epochs=8,print_cost=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
