{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Collaborative Filtering model\n",
    "\n",
    "For this particular model I will be using a dataset which consists of a series of books and their corresponding ratings from a set of users. My model is aimed at essentially learning how different books relate to one another and also allow for the prediction of how users might rate books they havn't already rated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from scipy.stats import norm\n",
    "import latex\n",
    "import random\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data and creating a matrix of user ratings\n",
    "\n",
    "Rows in the matrix will represent all of the different books while columns in the matrix will represent different users. The item at matrix[book i,user j] = rating(i,j). If there was no rating then this spot will be zero because rating are between 1 - 10 inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17384, 2946)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of total users = 2946\n",
    "# Number of total books = 17384\n",
    "matrix = np.zeros((17384,2946))\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File oriented as: user item rating\n",
    "with open(\"../data/book_data/book_ratings.dat\") as file:\n",
    "    lines = file.readlines()\n",
    "    i = 0\n",
    "    for line in lines:\n",
    "        if i != 0:\n",
    "            line = line.strip(\"\\n\")\n",
    "            aline = line.split()\n",
    "            matrix[int(aline[1])-1,int(aline[0])-1] = int(aline[2].split(\".\")[0])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the data with mean normalization\n",
    "\n",
    "Before using the matrix for learning, I am going to apply mean normalization. Specifically, I am getting the mean ratings for all books in the matrix and using that value to update the ratings for each book in the matrix.\n",
    "\n",
    "$$ Matrix = Matrix - \\mu $$\n",
    "\n",
    "I noticed that there are books with no rankings at all so I will be removing them from the original matrix and the mu vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_books = matrix.shape[0]\n",
    "mu = []\n",
    "nan_indexes = [] # saving indexes that \n",
    "\n",
    "for i in range(num_books):\n",
    "    ratings = matrix[i,:]\n",
    "    avg = np.asscalar(ratings[np.nonzero(ratings)].mean())\n",
    "    if ratings[np.nonzero(ratings)].shape == (0,): # no ratings\n",
    "        nan_indexes.append(i)\n",
    "    else:\n",
    "        mu.append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of mu vector: (14684, 1)\n"
     ]
    }
   ],
   "source": [
    "mu = np.array(mu)\n",
    "mu.shape = (14684,1)\n",
    "print(\"shape of mu vector:\",mu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of updated matrix: (14684, 2946)\n"
     ]
    }
   ],
   "source": [
    "matrix = np.delete(matrix,nan_indexes,axis=0)\n",
    "print(\"shape of updated matrix:\",matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14684, 2946)\n"
     ]
    }
   ],
   "source": [
    "# Mean normalization:\n",
    "matrix_norm = matrix\n",
    "for i in range(matrix_norm.shape[0]): # go through each book\n",
    "    for j in range(matrix_norm.shape[1]): # go through each user rating for a book\n",
    "        if matrix_norm[i,j] != 0:\n",
    "            matrix_norm[i,j] = matrix_norm[i,j] - mu[i]\n",
    "print(matrix_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building collaborative filtering model\n",
    "\n",
    "In this model I am attempting to learn both Theta, parameter vector for all users, and x, feature vector for each book. Note that I will be using regularization and I am choosing for there to be 4 features to learn.\n",
    "\n",
    "Cost function: Minimizing x<sup>(1)</sup>,...,x<sup>(n<sub>b</sub>)</sup> and Theta<sup>(1)</sup>,...,Theta<sup>(n<sub>u</sub>)</sup> simultaneously:\n",
    "\n",
    "$$ \\frac{1}{2} \\sum_{(i,j): r(i,j)=1} \\big( (\\theta^{(j)})^T x^{(i)} - y^{(i,j)} \\big)^2 \n",
    "   + \\frac{\\lambda}{2} \\sum^{n_b}_{i=1} \\sum^{n}_{k=1} (x^{(i)}_{k})^2 \n",
    "   + \\frac{\\lambda}{2} \\sum^{n_u}_{i=1} \\sum^{n}_{k=1} (\\theta^{(j)}_{k})^2 $$ \n",
    "\n",
    "Back prop to update x, theta:\n",
    "\n",
    "$$ x^{(i)}_k := x^{(i)}_k - \\alpha \\bigg( \\sum_{(i,j): r(i,j)=1} \\big( (\\theta^{(j)})^T x^{(i)} - y^{(i,j)} \\big) \\theta^{(j)}_k + \\lambda x^{(i)}_k \\bigg) $$\n",
    "\n",
    "$$ \\theta^{(j)}_k := \\theta^{(j)}_k - \\alpha \\bigg( \\sum_{(i,j): r(i,j)=1} \\big( (\\theta^{(j)})^T x^{(i)} - y^{(i,j)} \\big) x^{(i)}_k + \\lambda \\theta^{(j)}_k \\bigg) $$\n",
    "\n",
    "- n<sub>b</sub>: Number of total books\n",
    "- n<sub>u</sub>: Number of total users\n",
    "- r(i,j) = 1: Means there is a rating by user j for book i\n",
    "- y(i,j): rating by user j for book i\n",
    "- Theta<sup>(j)</sup>: Parameter vector for user j\n",
    "- x<sup>(i)</sup>: Parameter vector for book i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes theta parameters and x features with small randomized values from a uniform distribution\n",
    "# theta: shape(#users,4), x: shape(#books,4)\n",
    "def initialize_params(num_users, num_books, num_param):\n",
    "    x = np.random.normal(0, 0.05, (num_books,num_param))\n",
    "    theta = np.random.normal(0, 0.05, (num_users,num_param))\n",
    "    return x,theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns a list of tuples representing the indexes of all nonzero values as (book index, user index)\n",
    "We need this, as we are only computing the cost given indexes that actually have reviews\n",
    "\"\"\"\n",
    "def get_nonzero_indexes(matrix):\n",
    "    indexes = []\n",
    "    non_zero_i = np.nonzero(matrix)\n",
    "    book_i = non_zero_i[0]\n",
    "    user_i = non_zero_i[1]\n",
    "    \n",
    "    for i in range(len(book_i)):\n",
    "        indexes.append((book_i[i],user_i[i]))\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To compute the non-regularization term, this cost function only loops through entries that have reviews, this\n",
    "will ultimately cut down the number of items from 46.6 million to 74k, which is much more computationally reasonable\n",
    "\"\"\"\n",
    "def cost_function(matrix,x,theta,indexes,lam):\n",
    "    reg_x = (lam / 2) * np.sum(np.sum(np.square(x),axis=1))\n",
    "    reg_theta = (lam / 2) * np.sum(np.sum(np.square(theta),axis=1))\n",
    "    \n",
    "    cost = 0\n",
    "    for i in range(len(indexes)):\n",
    "        x_i = indexes[i][0]\n",
    "        theta_i = indexes[i][1]\n",
    "        ax = x[x_i,:] # shape(1,#features)\n",
    "        atheta = theta[theta_i,:] # shape(1,#features)\n",
    "        cost += np.square(np.dot(atheta.T,ax)-matrix[x_i,theta_i])\n",
    "    \n",
    "    final_cost = (1/2 * cost) + reg_x + reg_theta\n",
    "    return final_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Updates all of the x values, features for books\n",
    "\"\"\"\n",
    "def update_x(x,new_x,theta,matrix,indexes,alpha,lam,num_params):\n",
    "    \n",
    "    for i in range(x.shape[0]): # updating x values one at a time\n",
    "        ratings = [j for j in indexes if j[0] == i] # ratings for specific x, list of tuples\n",
    "        asum = np.zeros((num_params,))\n",
    "        for tup in ratings:\n",
    "            asum += (np.dot(theta[tup[1],:].T,x[tup[0],:]) - matrix[tup[0],tup[1]]) * theta[tup[1],:] + lam * x[tup[0],:]\n",
    "        \n",
    "        new_x[i,:] = new_x[i,:] - (alpha * asum)\n",
    "    \n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Updates all theta values, parameters for users\n",
    "\"\"\"\n",
    "def update_theta(theta,new_theta,x,matrix,indexes,alpha,lam,num_params):\n",
    "    \n",
    "    for i in range(theta.shape[0]): # updating theta values one at a time\n",
    "        ratings = [j for j in indexes if j[1] == i] # ratings for specific theta, list of tuples\n",
    "        asum = np.zeros((num_params,))\n",
    "        for tup in ratings:\n",
    "            asum += (np.dot(theta[tup[1],:].T,x[tup[0],:]) - matrix[tup[0],tup[1]]) * x[tup[0],:] + lam * theta[tup[1],:] \n",
    "        \n",
    "        new_theta[i,:] = new_theta[i,:] - (alpha * asum)\n",
    "    \n",
    "    return new_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Backprop step - returns updated matrices for x and theta\n",
    "\"\"\"\n",
    "def update_params(x,theta,matrix,indexes,alpha,lam,num_params):\n",
    "    new_x = x\n",
    "    new_theta = theta\n",
    "    \n",
    "    new_x = update_x(x,new_x,theta,matrix,indexes,alpha,lam,num_params)\n",
    "    new_theta = update_theta(theta,new_theta,x,matrix,indexes,alpha,lam,num_params)\n",
    "    \n",
    "    return new_x,new_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns a list of cost values along with the learned parameter matrices x,theta\n",
    "\"\"\"\n",
    "def model(matrix, alpha=0.1, lam=0.1, num_iter=100, print_cost=True,num_params=4):\n",
    "    costs = []\n",
    "    num_users = matrix.shape[1]\n",
    "    num_books = matrix.shape[0]\n",
    "    x,theta = initialize_params(num_users,num_books,num_params)\n",
    "    indexes = get_nonzero_indexes(matrix)\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        x,theta = update_params(x,theta,matrix,indexes,alpha,lam,num_params) # update params\n",
    "        \n",
    "        if i % 1 == 0 and print_cost:\n",
    "            cost = cost_function(matrix,x,theta,indexes,lam)\n",
    "            costs.append(cost)\n",
    "            print(\"cost at epoch \"+str(i+1)+\": \"+str(cost))\n",
    "            \n",
    "    return costs,x,theta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at epoch 1: 64247.53308885036\n",
      "cost at epoch 2: 64232.74246028733\n",
      "cost at epoch 3: 64214.04128826246\n",
      "cost at epoch 4: 64186.826878456144\n",
      "cost at epoch 5: 64141.13447430443\n",
      "cost at epoch 6: 64054.349679927065\n",
      "cost at epoch 7: 63877.58055123876\n",
      "cost at epoch 8: 63526.68685234158\n",
      "cost at epoch 9: 62939.2550958964\n",
      "cost at epoch 10: 62195.67037028232\n",
      "cost at epoch 11: 61345.214753421555\n",
      "cost at epoch 12: 60365.83022477897\n",
      "cost at epoch 13: 59412.53608262942\n",
      "cost at epoch 14: 58459.947462754106\n",
      "cost at epoch 15: 57423.91717389084\n",
      "cost at epoch 16: 56312.12629374273\n",
      "cost at epoch 17: 55156.11329355991\n",
      "cost at epoch 18: 53981.238066539125\n",
      "cost at epoch 19: 52807.87841235516\n",
      "cost at epoch 20: 51654.13679893898\n",
      "cost at epoch 21: 50533.239701759994\n",
      "cost at epoch 22: 49451.26559861989\n",
      "cost at epoch 23: 48409.00902712231\n",
      "cost at epoch 24: 47405.60208926375\n",
      "cost at epoch 25: 46440.78952765072\n",
      "cost at epoch 26: 45515.35880402278\n",
      "cost at epoch 27: 44630.645283333346\n",
      "cost at epoch 28: 43787.91830116793\n",
      "cost at epoch 29: 42987.95470964923\n",
      "cost at epoch 30: 42230.824291098266\n",
      "cost at epoch 31: 41515.851880197355\n",
      "cost at epoch 32: 40841.71667166284\n",
      "cost at epoch 33: 40206.63015218412\n",
      "cost at epoch 34: 39608.52583162354\n",
      "cost at epoch 35: 39045.21515621944\n",
      "cost at epoch 36: 38514.496473113635\n",
      "cost at epoch 37: 38014.22507608269\n",
      "cost at epoch 38: 37542.3574297516\n",
      "cost at epoch 39: 37096.979026984496\n",
      "cost at epoch 40: 36676.320517938904\n",
      "cost at epoch 41: 36278.76393940246\n",
      "cost at epoch 42: 35902.84012366871\n",
      "cost at epoch 43: 35547.2187187311\n",
      "cost at epoch 44: 35210.69283216231\n",
      "cost at epoch 45: 34892.1606387368\n",
      "cost at epoch 46: 34590.60623777027\n",
      "cost at epoch 47: 34305.08169485548\n",
      "cost at epoch 48: 34034.69168461008\n",
      "cost at epoch 49: 33778.581570988455\n",
      "cost at epoch 50: 33535.92917925998\n",
      "cost at epoch 51: 33305.94000705231\n",
      "cost at epoch 52: 33087.84525203839\n",
      "cost at epoch 53: 32880.90187587725\n",
      "cost at epoch 54: 32684.39393277948\n",
      "cost at epoch 55: 32497.634562769184\n",
      "cost at epoch 56: 32319.968193513796\n",
      "cost at epoch 57: 32150.77272003456\n",
      "cost at epoch 58: 31989.461399471944\n",
      "cost at epoch 59: 31835.484471066713\n",
      "cost at epoch 60: 31688.33010230961\n",
      "cost at epoch 61: 31547.525068836858\n",
      "cost at epoch 62: 31412.634082438566\n",
      "cost at epoch 63: 31283.259658721505\n",
      "cost at epoch 64: 31159.0387016459\n",
      "cost at epoch 65: 31039.64355994346\n",
      "cost at epoch 66: 30924.772101729846\n",
      "cost at epoch 67: 30814.159110268196\n",
      "cost at epoch 68: 30707.542309851946\n",
      "cost at epoch 69: 30604.724485788545\n",
      "cost at epoch 70: 30505.430351642033\n",
      "cost at epoch 71: 30409.61003979859\n",
      "cost at epoch 72: 30316.76760786594\n",
      "cost at epoch 73: 30227.464287017952\n",
      "cost at epoch 74: 30140.026535045406\n",
      "cost at epoch 75: 30058.487065667432\n",
      "cost at epoch 76: 29977.122328907735\n",
      "cost at epoch 77: 29930.799137596878\n",
      "cost at epoch 78: 29970.348455887754\n",
      "cost at epoch 79: 30557.99905829376\n",
      "cost at epoch 80: 33614.56700612443\n",
      "cost at epoch 81: 30233.576624261532\n",
      "cost at epoch 82: 29835.089854221067\n",
      "cost at epoch 83: 29764.85416626939\n",
      "cost at epoch 84: 29745.455143635318\n",
      "cost at epoch 85: 30019.87749026626\n",
      "cost at epoch 86: 30273.275186298353\n",
      "cost at epoch 87: 30217.86781695183\n",
      "cost at epoch 88: 29909.632328703345\n",
      "cost at epoch 89: 29627.77045488501\n",
      "cost at epoch 90: 29549.48420758425\n",
      "cost at epoch 91: 29673.84201595431\n",
      "cost at epoch 92: 29986.531866130394\n",
      "cost at epoch 93: 30467.40132099031\n",
      "cost at epoch 94: 30776.187176476942\n",
      "cost at epoch 95: 30733.316799492968\n",
      "cost at epoch 96: 30544.18236138699\n",
      "cost at epoch 97: 30113.355318047863\n",
      "cost at epoch 98: 29910.284745042434\n",
      "cost at epoch 99: 29768.69178416336\n",
      "cost at epoch 100: 29584.776294645373\n"
     ]
    }
   ],
   "source": [
    "a_costs,a_x,a_theta = model(matrix_norm, 0.01, 0.01, 100, True, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"x.npy\",a_x)\n",
    "np.save(\"theta.npy\",a_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14684, 2)\n",
      "(2946, 2)\n"
     ]
    }
   ],
   "source": [
    "# Shape of learned parameters\n",
    "print(a_x.shape)\n",
    "print(a_theta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using learned parameters to predict user ratings and find books that are similar \n",
    "Note that the model hasn't reached a minimum, but that isn't strict necessary to show how user ratings would be predicted or how to find books that are similar to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14684, 2946)\n"
     ]
    }
   ],
   "source": [
    "# Getting predicted user ratings\n",
    "pred_ratings = np.dot(a_x,a_theta.T)\n",
    "pred_ratings = pred_ratings + mu # Adding back mean\n",
    "print(pred_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.92111225, 6.07137104, 6.00398393, ..., 6.00311499, 5.99266823,\n",
       "        6.00500183],\n",
       "       [8.36575081, 9.21881347, 8.36455664, ..., 8.34683881, 7.55040565,\n",
       "        8.3696176 ],\n",
       "       [9.99430902, 7.64533903, 8.68791821, ..., 8.70120764, 8.84752976,\n",
       "        8.67198906],\n",
       "       ...,\n",
       "       [5.96597223, 5.86992134, 5.99594012, ..., 5.99874368, 6.13504085,\n",
       "        5.99541569],\n",
       "       [8.22380668, 8.20254143, 8.00324613, ..., 7.99770885, 7.67283262,\n",
       "        8.00278421],\n",
       "       [6.84816081, 6.1314815 , 6.48049454, ..., 6.48538722, 6.57834857,\n",
       "        6.47568156]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the book most similar to a given book\n",
    "This is done by comparing the distance of the feature vectors of both books. A small distance indicated that two books are similar.\n",
    "\n",
    "$$ || x^{(i)} - x^{(j)} || $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computes the distance between two vectors of shape (2,)\n",
    "\"\"\"\n",
    "def distance(vec_a, vec_b):\n",
    "    return np.sum(np.square(vec_a - vec_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "# Finding five books most similar to the first book\n",
    "book_1 = a_x[0,:]\n",
    "print(book_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the most similar book to the first book\n",
    "smallest_dist = 1000\n",
    "closest_book = () # (book id, dist value, features)\n",
    "\n",
    "for i in range(1,a_x.shape[0]):\n",
    "    temp_features = a_x[i,:]\n",
    "    dist = distance(book_1, temp_features)\n",
    "    if dist < smallest_dist:\n",
    "        smallest_dist = dist\n",
    "        closest_book = (i,smallest_dist,temp_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10515, 1.933215741400255e-06, array([-0.0435839, -0.026784 ]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Found that book at index 10515 is the closest to the book at index 0\n",
    "closest_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
