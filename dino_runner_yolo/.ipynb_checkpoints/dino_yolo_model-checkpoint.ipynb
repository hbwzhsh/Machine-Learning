{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO_v3 inspired model\n",
    "\n",
    "- This model takes in input images of shape (720,720,1) and produces output of shape (15,15,14). Given the k-means clustering analysis done in the clean data step, there are two distinct clusters of images corresponding to open and closed palm. This is due to the inherent image ratio of an open and closed palm. With these two clusters, I am building the model to recognize these two different ratios. the y output shape is (15,15,7).\n",
    "- This model is inpsired by the YOLO_v3 model and as such is comprised of residual blocks, batch normalization, and other structural elements.\n",
    "- I will be using mini-batch gradient descent with adam optimization, but will not be using an iteratively decreasing learning rate\n",
    "\n",
    "Note - given time constraints, within this current iteration of the model I am using one prediction per cell rather than 2 specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import latex\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading training data, shuffling, and creating a test subset for testing model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396, 720, 720, 1)\n",
      "(396, 15, 15, 7)\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "X = np.load(\"../../data/dinorunner/images.npy\")\n",
    "y = np.load(\"../../data/dinorunner/encodings.npy\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing image data\n",
    "X = X / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396, 720, 720, 1)\n",
      "(396, 15, 15, 7)\n"
     ]
    }
   ],
   "source": [
    "# shuffling the data \n",
    "X = shuffle(X,random_state=1)\n",
    "y = shuffle(y,random_state=1)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'Dimension' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4b539739f5d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Creating testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2054\u001b[0m                      random_state=random_state)\n\u001b[1;32m   2055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1202\u001b[0m         \"\"\"\n\u001b[1;32m   1203\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1302\u001b[0m         n_train, n_test = _validate_shuffle_split(n_samples,\n\u001b[1;32m   1303\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                                                   self.train_size)\n\u001b[0m\u001b[1;32m   1305\u001b[0m         \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size)\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'f'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0mn_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'i'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m         \u001b[0mn_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__rmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    258\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mDimension\u001b[0m \u001b[0mwhose\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproduct\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mother\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__floordiv__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'Dimension' and 'float'"
     ]
    }
   ],
   "source": [
    "# Creating testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ay = np.zeros((1,15,15,7))\n",
    "ay[0,0,0,:] = np.array([1,0.5,0.5,0.25,0.25,1,0]) # top left corner\n",
    "az = np.zeros((1,15,15,14))\n",
    "az[0,0,0,0:7] = np.array([0.8,0.25,0.25,0.2,0.2,0.8,0.2])\n",
    "az[0,0,1,0] = 1\n",
    "az[0,1,0,0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building YOLO model\n",
    "\n",
    "#### YOLO cost function:\n",
    "\n",
    "$$ \\lambda_{coord} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} 1_{ij}^{obj} \\bigg[(x_i-\\hat{x_{i}})^2 + (y_i - \\hat{y_i})^2\\bigg]$$\n",
    "$$ + \\lambda_{coord} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} 1_{ij}^{obj} \\bigg[(\\sqrt{w_i}-\\sqrt{\\hat{w_{i}}})^2 + (\\sqrt{h_i} - \\sqrt{\\hat{h_i}})^2\\bigg] $$\n",
    "$$ + \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} 1_{ij}^{obj} (c_i-\\hat{c_{i}})^2 $$\n",
    "$$ + \\lambda_{noobj} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} 1_{ij}^{noobj} (c_i-\\hat{c_{i}})^2 $$\n",
    "$$ \\sum_{i=0}^{S^{2}} 1_{i}^{obj} \\sum_{c \\in classes} (p_i(c)-\\hat{p_{i}}(c))^2 $$\n",
    "\n",
    "Note - the ground truth box in B will be the box that has the highest IoU with the true box\n",
    "\n",
    "Terms:\n",
    "- S<sup>2</sup>: the number of cells in an image (15x15)\n",
    "- B: all bounding boxes per cell (1) \n",
    "- 1<sup>obj</sup><sub>ij</sub>: denotes the bounding box predictor in cell (i,j) responsible for prediction\n",
    "- 1<sup>obj</sup><sub>ij</sub>: denotes if object appears in cell\n",
    "- C<sub>i</sub>: confidence score for whether there is an object\n",
    "- lambda<sub>coord</sub>: (5) weight factor that increases loss from bounding box predictions \n",
    "- lambda<sub>noobj</sub>: (0.5) weight factor that decreases loss from predictions for boxes that don't contain objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder values for input X,y data\n",
    "def get_placeholders(x_h,x_w,x_c,y_h,y_w,y_c):\n",
    "    \"\"\"\n",
    "    x_h: Height for x input \n",
    "    x_w: Width for x input\n",
    "    x_c: Channels for x input\n",
    "    y_h: Height for y input\n",
    "    y_w: Width for y input\n",
    "    y_c: Channels for y input\n",
    "    \"\"\"\n",
    "    X = tf.placeholder(tf.float32, name=\"X\", shape=(None,x_h,x_w,x_c))\n",
    "    y = tf.placeholder(tf.float32, name=\"y\", shape=(None,y_h,y_w,y_c))\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (?, 720, 720, 1)\n",
      "y shape: (?, 15, 15, 14)\n"
     ]
    }
   ],
   "source": [
    "# Testing placeholders\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    X,y = get_placeholders(720,720,1,15,15,14)\n",
    "    print(\"X shape:\",X.shape)\n",
    "    print(\"y shape:\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow forward prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Standard residual block which has the same input shape as output shape\n",
    "Correspond with 1. conv2d filter(1,1) \"valid\" 2. conv2d filter(3,3) \"same\"\n",
    "\"\"\"\n",
    "def same_identity(the_input,nf,sl):\n",
    "    \"\"\"\n",
    "    the_input: outut from a previous layer of conv net\n",
    "    nf: number of filters for the same_identity block\n",
    "    sl: the number of the first layer in this block\n",
    "    \"\"\"\n",
    "    shortcut = the_input # saving previous activation\n",
    "    \n",
    "    Z1 = tf.layers.conv2d(the_input,filters=nf,kernel_size=[1,1],strides=(1,1),padding=\"valid\",name=\"Z\"+str(sl),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    Bn1 = tf.layers.batch_normalization(Z1,name=\"Bn\"+str(sl))\n",
    "    A1 = tf.nn.leaky_relu(Bn1,alpha=0.1,name=\"A\"+str(sl))\n",
    "    \n",
    "    Z2 = tf.layers.conv2d(A1,filters=nf,kernel_size=[3,3],strides=(1,1),padding=\"same\",name=\"Z\"+str(sl+1),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    Bn2 = tf.layers.batch_normalization(Z2,name=\"Bn\"+str(sl+1))\n",
    "    \n",
    "    # updating old residual to new size and channel\n",
    "    shortcut_Z = tf.layers.conv2d(shortcut,filters=nf,kernel_size=[3,3],strides=(1,1),padding=\"same\",name=\"shortcut_Z\"+str(sl+1),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    shortcut_Bn = tf.layers.batch_normalization(shortcut_Z,name=\"shortcut_Bn\"+str(sl+1))\n",
    "    newZ = tf.add(Bn2,shortcut_Bn,name=\"resid_add\"+str(sl+1)) # adding old residual\n",
    "    A2 = tf.nn.leaky_relu(newZ,alpha=0.1,name=\"A\"+str(sl+1))\n",
    "    \n",
    "    return A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Standard residual block which does not have the same input shape as output shape\n",
    "Correspond with 1. conv2d filter(1,1) \"valid\" 2. conv2d filter(3,3) \"valid\"\n",
    "\"\"\"\n",
    "def valid_identity(the_input,nf,sl):\n",
    "    shortcut = the_input # saving previous activation\n",
    "    \n",
    "    Z1 = tf.layers.conv2d(the_input,filters=nf,kernel_size=[1,1],strides=(1,1),padding=\"valid\",name=\"Z\"+str(sl),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    Bn1 = tf.layers.batch_normalization(Z1,name=\"Bn\"+str(sl))\n",
    "    A1 = tf.nn.leaky_relu(Bn1,alpha=0.1,name=\"A\"+str(sl))\n",
    "    \n",
    "    Z2 = tf.layers.conv2d(A1,filters=nf,kernel_size=[3,3],strides=(1,1),padding=\"valid\",name=\"Z\"+str(sl+1),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    Bn2 = tf.layers.batch_normalization(Z2,name=\"Bn\"+str(sl+1))\n",
    "    \n",
    "    # updating old residual to new size and channel\n",
    "    shortcut_Z = tf.layers.conv2d(shortcut,filters=nf,kernel_size=[3,3],strides=(1,1),padding=\"valid\",name=\"shortcut_Z\"+str(sl+1),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    shortcut_Bn = tf.layers.batch_normalization(shortcut_Z,name=\"shortcut_Bn\"+str(sl+1))\n",
    "    newZ = tf.add(Bn2,shortcut_Bn,name=\"resid_add\"+str(sl+1)) # adding old residual\n",
    "    A2 = tf.nn.leaky_relu(newZ,alpha=0.1,name=\"A\"+str(sl+1))\n",
    "    \n",
    "    return A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Forward pass using residual blocks, batch normalization, leaky relu\n",
    "Note that these reside blocks jump over a single layer\n",
    "\"\"\"\n",
    "def forward_pass(X,out):\n",
    "    \"\"\"\n",
    "    Input image or images: X -shape(?,720,720,1)\n",
    "    out - specifies how many predictions per cell you want, multiple of 7\n",
    "    \"\"\"\n",
    "    # First layer\n",
    "    input_layer = tf.reshape(X,[-1,720,720,1])\n",
    "    Z = tf.layers.conv2d(input_layer,filters=4,kernel_size=[5,5],strides=(1,1),padding=\"same\",name=\"Z1\",kernel_initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    Bn = tf.layers.batch_normalization(Z,name=\"Bn1\")\n",
    "    A = tf.nn.leaky_relu(Bn,alpha=0.1,name=\"A1\")\n",
    "    P1 = tf.layers.max_pooling2d(A,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P1\") # shape (358,358,4)\n",
    "    # Block 1\n",
    "    B1 = same_identity(P1,8,2)\n",
    "    B2 = valid_identity(B1,16,4)\n",
    "    B2_pool = tf.layers.max_pooling2d(B2,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P1\") # shape (178,178,16)\n",
    "    # Block 2\n",
    "    B3 = same_identity(B2_pool,32,6)\n",
    "    B4 = valid_identity(B3,64,8)\n",
    "    B4_pool = tf.layers.max_pooling2d(B4,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P2\") # shape (88,88,64)\n",
    "    # Block 3\n",
    "    B5 = same_identity(B4_pool,128,10)\n",
    "    B6 = valid_identity(B5,256,12)\n",
    "    B7 = same_identity(B6,128,14)\n",
    "    B8 = valid_identity(B7,256,16)\n",
    "    B8_pool = tf.layers.max_pooling2d(B8,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P3\") # shape (42,42,256)\n",
    "    # Block 4\n",
    "    B9 = same_identity(B8_pool,256,18)\n",
    "    B10 = valid_identity(B9,512,20)\n",
    "    B11 = same_identity(B10,256,22)\n",
    "    B12 = valid_identity(B11,512,24)\n",
    "    B12_pool = tf.layers.max_pooling2d(B12,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P4\") # shape (19,19,512)\n",
    "    # Block 5\n",
    "    B13 = same_identity(B12_pool,512,26)\n",
    "    B14 = valid_identity(B13,1024,28)\n",
    "    B15 = same_identity(B14,512,30)\n",
    "    B16 = valid_identity(B15,1024,32) # shape (15,15,1024)\n",
    "    # Final layer - no batch norm, linear activation\n",
    "    Z34 = tf.layers.conv2d(B16,filters=out,kernel_size=[1,1],strides=(1,1),padding=\"valid\",name=\"Z34\",activation=None)\n",
    "    return Z34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z shape: (3, 15, 15, 14)\n"
     ]
    }
   ],
   "source": [
    "# Testing forward prop\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X,y = get_placeholders(720,720,1,15,15,7)\n",
    "    Z34 = forward_pass(X,out=14)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    aZ = sess.run(Z34,feed_dict={X:np.random.randn(3,720,720,1),y:np.random.randn(3,15,15,7)})\n",
    "    print(\"Z shape:\", str(aZ.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the values with a specific mask applied to it\n",
    "def get_box_values(box,mask):\n",
    "    \"\"\"\n",
    "    Index:\n",
    "    0: confidence there is an object in cell, 1: mid_x, 2: mid_y, \n",
    "    3: width, 4: length, 5: prob_open_palm, 6: prob_close_palm\n",
    "    \"\"\"\n",
    "    confidence = tf.boolean_mask(box[:,:,:,0:1],mask)\n",
    "    mid_x = tf.boolean_mask(box[:,:,:,1:2],mask)\n",
    "    mid_y = tf.boolean_mask(box[:,:,:,2:3],mask)\n",
    "    width = tf.boolean_mask(box[:,:,:,3:4],mask)\n",
    "    length = tf.boolean_mask(box[:,:,:,4:5],mask)\n",
    "    prob_dog = tf.boolean_mask(box[:,:,:,5:6],mask)\n",
    "    prob_cat = tf.boolean_mask(box[:,:,:,6:7],mask)\n",
    "    box = {\"co\":confidence, \"mx\":mid_x,\"my\":mid_y,\"w\":width,\"l\":length,\"d\":prob_dog,\"c\":prob_cat}\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A component of this cost function is that it heavily penalizes negative predictions for height and weight\n",
    "# This choice was made due to the reality that it is impossible to have a negative height or width\n",
    "# This cost function functions when there is one prediction per cell\n",
    "def cost_function(Z,y,coord=5,noobj=0.5):\n",
    "    \"\"\"\n",
    "    Z - shape (?,15,15,7)\n",
    "    y - shape (?,15,15,7)\n",
    "    \"\"\"\n",
    "    c_mask_true = y[:,:,:,0:1] > 0\n",
    "    c_mask_false = y[:,:,:,0:1] < 1\n",
    "    \n",
    "    y_v = get_box_values(y,c_mask_true)\n",
    "    m_v = get_box_values(Z,c_mask_true)\n",
    "    mv_f = get_box_values(Z,c_mask_false)\n",
    "    y_f = get_box_values(y,c_mask_false)\n",
    "    \n",
    "    # seeing if pred width and height are positive\n",
    "    m_v[\"w\"] = tf.cond(tf.reshape(m_v[\"w\"],[])>0, lambda: tf.sqrt(m_v[\"w\"]), lambda: m_v[\"w\"])\n",
    "    m_v[\"l\"] = tf.cond(tf.reshape(m_v[\"l\"],[])>0, lambda: tf.sqrt(m_v[\"l\"]), lambda: m_v[\"l\"])\n",
    "    \n",
    "    y_v[\"w\"] = tf.sqrt(y_v[\"w\"])\n",
    "    y_v[\"l\"] = tf.sqrt(y_v[\"l\"])\n",
    "    \n",
    "    # correspond to individual summations of the cost function:\n",
    "    part1 = coord * tf.reduce_sum(tf.square(y_v[\"mx\"]-m_v[\"mx\"])+tf.square(y_v[\"my\"]-m_v[\"my\"]))\n",
    "    part2 = coord * tf.reduce_sum(tf.square(y_v[\"w\"]-m_v[\"w\"])+tf.square(y_v[\"l\"]-m_v[\"l\"]))\n",
    "    part3 = tf.reduce_sum(tf.square(y_v[\"co\"]-m_v[\"co\"]))\n",
    "    part4 = noobj * tf.reduce_sum(tf.square(y_f[\"co\"]-mv_f[\"co\"]))\n",
    "    part5 = tf.reduce_sum(tf.add(tf.square(y_v[\"d\"]-m_v[\"d\"]),tf.square(y_v[\"c\"]-m_v[\"c\"])))# if obj in cell, if bounding box is highest IoU, compare class predictions\n",
    "    total_cost = part1 + part2 + part3 + part4 + part5\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7728641\n"
     ]
    }
   ],
   "source": [
    "# Testing cost function\n",
    "# predicted cost 2/ rounding error is 1.773\n",
    "ay = np.zeros((1,15,15,7))\n",
    "ay[0,0,0,:] = np.array([1,0.5,0.5,0.25,0.25,1,0]) # top left corner\n",
    "az = np.zeros((1,15,15,14))\n",
    "az[0,0,0,0:7] = np.array([0.8,0.25,0.25,0.2,0.2,0.8,0.2])\n",
    "az[0,0,1,0] = 1\n",
    "az[0,1,0,0] = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    y = tf.placeholder(tf.float32,shape=(None,15,15,7))\n",
    "    Z = tf.placeholder(tf.float32,shape=(None,15,15,14))\n",
    "    aCost = cost_function(Z,y)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    tot = sess.run(aCost,feed_dict={Z:az,y:ay})\n",
    "    print(tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates shuffled mini batches\n",
    "def random_mini_batches(X, y, mini_batch_size, seed):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    rounds = int(X.shape[0] / mini_batch_size) # Max number of minibatches\n",
    "    X_shuffle = shuffle(X, random_state=seed)\n",
    "    y_shuffle = shuffle(y, random_state=seed)\n",
    "    mini_batches = []\n",
    "    a = 0 #used to siphon off sections of X\n",
    "    b = 0 #used to siphon off sections of y\n",
    "    \n",
    "    for around in range(rounds):\n",
    "        x_mini = X_shuffle[a:a+mini_batch_size]\n",
    "        y_mini = y_shuffle[b:b+mini_batch_size]\n",
    "        mini_batch = (x_mini,y_mini)\n",
    "        mini_batches.append(mini_batch)\n",
    "        a += mini_batch_size\n",
    "        b += mini_batch_size\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building and training YOLO model\n",
    "def model(X_train,y_train,lr=0.001,minibatch_size=10,num_epochs=200,print_cost=True):\n",
    "    tf.reset_default_graph() # resetting graph\n",
    "    tf.set_random_seed(1)\n",
    "    seed=0\n",
    "    out=7 # specifying number of guesses per cell\n",
    "    costs=[]\n",
    "    x_h = X_train[0].shape[0]\n",
    "    x_w = X_train[0].shape[1]\n",
    "    x_c = X_train[0].shape[2]\n",
    "    y_h = y_train[0].shape[0]\n",
    "    y_w = y_train[0].shape[1]\n",
    "    y_c = y_train[0].shape[2]\n",
    "    m = X_train.shape[0]\n",
    "    \n",
    "    X,y = get_placeholders(x_h,x_w,x_c,y_h,y_w,y_c)\n",
    "    Z = forward_pass(X,out)\n",
    "    cost = cost_function(Z,y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        # Loading saved model\n",
    "        #saver = tf.train.import_meta_graph(\"../../structured_dl_files/models/yolo_model.ckpt.meta\")\n",
    "        #saver.restore(sess, \"../../structured_dl_files/models/yolo_model.ckpt\")\n",
    "        sess.run(init) # DONT RUN INIT IF LOADING MODEL\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            minibatch_cost = 0\n",
    "            seed += 1\n",
    "            minibatches = random_mini_batches(X_train, y_train, minibatch_size, seed)\n",
    "            \n",
    "            for minibatch in minibatches:\n",
    "                (mini_x,mini_y) = minibatch\n",
    "                _,temp_cost = sess.run([optimizer,cost], feed_dict={X:mini_x,y:mini_y})\n",
    "                minibatch_cost += temp_cost\n",
    "                \n",
    "            costs.append(cost)\n",
    "            if print_cost and epoch % 1 == 0:\n",
    "                print(\"Cost at epoch {}: {}\".format(epoch+1,minibatch_cost))\n",
    "                \n",
    "        loc = saver.save(sess, \"../../data/dinorunner/models/yolo_model.ckpt\")\n",
    "        return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
