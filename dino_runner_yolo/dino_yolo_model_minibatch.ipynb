{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note - In this model I play around with ways to create a resnet model less than 53 layers to reduce training time. Ultimately I do not use this model for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO_v3 inspired model\n",
    "\n",
    "- This model takes in input images of shape (720,720,1) and produces output of shape (15,15,7). Note that I do not take advantage of the clustering I did in the training notebook for this specific model.\n",
    "- This model is inpsired by the YOLO_v3 model and as such is comprised of residual blocks, batch normalization, and other structural elements.\n",
    "- I will be using mini-batch gradient descent with adam optimization, but will not be using an iteratively decreasing learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import latex\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading training data, shuffling, and creating a test subset for testing model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396, 720, 720, 1)\n",
      "(396, 15, 15, 7)\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "X = np.load(\"../../data/dinorunner/images.npy\")\n",
    "y = np.load(\"../../data/dinorunner/encodings.npy\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing image data\n",
    "X = X / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396, 720, 720, 1)\n",
      "(396, 15, 15, 7)\n"
     ]
    }
   ],
   "source": [
    "# shuffling the data \n",
    "X = shuffle(X,random_state=1)\n",
    "y = shuffle(y,random_state=1)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376, 720, 720, 1)\n",
      "(376, 15, 15, 7)\n",
      "(20, 720, 720, 1)\n",
      "(20, 15, 15, 7)\n"
     ]
    }
   ],
   "source": [
    "# Creating testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building YOLO model\n",
    "\n",
    "#### YOLO cost function:\n",
    "\n",
    "$$ \\lambda_{coord} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} 1_{ij}^{obj} \\bigg[(x_i-\\hat{x_{i}})^2 + (y_i - \\hat{y_i})^2\\bigg]$$\n",
    "$$ + \\lambda_{coord} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} 1_{ij}^{obj} \\bigg[(\\sqrt{w_i}-\\sqrt{\\hat{w_{i}}})^2 + (\\sqrt{h_i} - \\sqrt{\\hat{h_i}})^2\\bigg] $$\n",
    "$$ + \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} 1_{ij}^{obj} (c_i-\\hat{c_{i}})^2 $$\n",
    "$$ + \\lambda_{noobj} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} 1_{ij}^{noobj} (c_i-\\hat{c_{i}})^2 $$\n",
    "$$ \\sum_{i=0}^{S^{2}} 1_{i}^{obj} \\sum_{c \\in classes} (p_i(c)-\\hat{p_{i}}(c))^2 $$\n",
    "\n",
    "Note - the ground truth box in B will be the box that has the highest IoU with the true box\n",
    "\n",
    "Terms:\n",
    "- S<sup>2</sup>: the number of cells in an image (15x15)\n",
    "- B: all bounding boxes per cell (1) \n",
    "- 1<sup>obj</sup><sub>ij</sub>: denotes the bounding box predictor in cell (i,j) responsible for prediction\n",
    "- 1<sup>obj</sup><sub>ij</sub>: denotes if object appears in cell\n",
    "- C<sub>i</sub>: confidence score for whether there is an object\n",
    "- lambda<sub>coord</sub>: (5) weight factor that increases loss from bounding box predictions \n",
    "- lambda<sub>noobj</sub>: (0.5) weight factor that decreases loss from predictions for boxes that don't contain objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder values for input X,y data\n",
    "def get_placeholders(x_h,x_w,x_c,y_h,y_w,y_c):\n",
    "    \"\"\"\n",
    "    x_h: Height for x input \n",
    "    x_w: Width for x input\n",
    "    x_c: Channels for x input\n",
    "    y_h: Height for y input\n",
    "    y_w: Width for y input\n",
    "    y_c: Channels for y input\n",
    "    \"\"\"\n",
    "    X = tf.placeholder(tf.float32, name=\"X\", shape=(None,x_h,x_w,x_c))\n",
    "    y = tf.placeholder(tf.float32, name=\"y\", shape=(None,y_h,y_w,y_c))\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (?, 720, 720, 1)\n",
      "y shape: (?, 15, 15, 14)\n"
     ]
    }
   ],
   "source": [
    "# Testing placeholders\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    X,y = get_placeholders(720,720,1,15,15,14)\n",
    "    print(\"X shape:\",X.shape)\n",
    "    print(\"y shape:\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow forward prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Standard residual block which has the same input shape as output shape\n",
    "Correspond with 1. conv2d filter(1,1) \"valid\" 2. conv2d filter(3,3) \"same\"\n",
    "\"\"\"\n",
    "def same_identity(the_input,nf,sl):\n",
    "    \"\"\"\n",
    "    the_input: outut from a previous layer of conv net\n",
    "    nf: number of filters for the same_identity block\n",
    "    sl: the number of the first layer in this block\n",
    "    \"\"\"\n",
    "    shortcut = the_input # saving previous activation\n",
    "    \n",
    "    Z1 = tf.layers.conv2d(the_input,filters=nf,kernel_size=[1,1],strides=(1,1),padding=\"valid\",name=\"Z\"+str(sl),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    Bn1 = tf.layers.batch_normalization(Z1,name=\"Bn\"+str(sl))\n",
    "    A1 = tf.nn.leaky_relu(Bn1,alpha=0.1,name=\"A\"+str(sl))\n",
    "    \n",
    "    Z2 = tf.layers.conv2d(A1,filters=nf,kernel_size=[3,3],strides=(1,1),padding=\"same\",name=\"Z\"+str(sl+1),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    Bn2 = tf.layers.batch_normalization(Z2,name=\"Bn\"+str(sl+1))\n",
    "    \n",
    "    # updating old residual to new size and channel\n",
    "    shortcut_Z = tf.layers.conv2d(shortcut,filters=nf,kernel_size=[3,3],strides=(1,1),padding=\"same\",name=\"shortcut_Z\"+str(sl+1),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    shortcut_Bn = tf.layers.batch_normalization(shortcut_Z,name=\"shortcut_Bn\"+str(sl+1))\n",
    "    newZ = tf.add(Bn2,shortcut_Bn,name=\"resid_add\"+str(sl+1)) # adding old residual\n",
    "    A2 = tf.nn.leaky_relu(newZ,alpha=0.1,name=\"A\"+str(sl+1))\n",
    "    \n",
    "    return A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Standard residual block which does not have the same input shape as output shape\n",
    "Correspond with 1. conv2d filter(1,1) \"valid\" 2. conv2d filter(3,3) \"valid\"\n",
    "\"\"\"\n",
    "def valid_identity(the_input,nf,sl):\n",
    "    shortcut = the_input # saving previous activation\n",
    "    \n",
    "    Z1 = tf.layers.conv2d(the_input,filters=nf,kernel_size=[1,1],strides=(1,1),padding=\"valid\",name=\"Z\"+str(sl),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    Bn1 = tf.layers.batch_normalization(Z1,name=\"Bn\"+str(sl))\n",
    "    A1 = tf.nn.leaky_relu(Bn1,alpha=0.1,name=\"A\"+str(sl))\n",
    "    \n",
    "    Z2 = tf.layers.conv2d(A1,filters=nf,kernel_size=[3,3],strides=(1,1),padding=\"valid\",name=\"Z\"+str(sl+1),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    Bn2 = tf.layers.batch_normalization(Z2,name=\"Bn\"+str(sl+1))\n",
    "    \n",
    "    # updating old residual to new size and channel\n",
    "    shortcut_Z = tf.layers.conv2d(shortcut,filters=nf,kernel_size=[3,3],strides=(1,1),padding=\"valid\",name=\"shortcut_Z\"+str(sl+1),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    shortcut_Bn = tf.layers.batch_normalization(shortcut_Z,name=\"shortcut_Bn\"+str(sl+1))\n",
    "    newZ = tf.add(Bn2,shortcut_Bn,name=\"resid_add\"+str(sl+1)) # adding old residual\n",
    "    A2 = tf.nn.leaky_relu(newZ,alpha=0.1,name=\"A\"+str(sl+1))\n",
    "    \n",
    "    return A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Forward pass using residual blocks, batch normalization, leaky relu\n",
    "Note that these reside blocks jump over a single layer\n",
    "\"\"\"\n",
    "def forward_pass(X,out):\n",
    "    \"\"\"\n",
    "    Input image or images: X -shape(?,720,720,1)\n",
    "    out - specifies how many predictions per cell you want, multiple of 7\n",
    "    \"\"\"\n",
    "    # First layer\n",
    "    input_layer = tf.reshape(X,[-1,720,720,1])\n",
    "    Z = tf.layers.conv2d(input_layer,filters=4,kernel_size=[5,5],strides=(1,1),padding=\"same\",name=\"Z1\",kernel_initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    Bn = tf.layers.batch_normalization(Z,name=\"Bn1\")\n",
    "    A = tf.nn.leaky_relu(Bn,alpha=0.1,name=\"A1\")\n",
    "    P1 = tf.layers.max_pooling2d(A,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P1\") # shape (358,358,4)\n",
    "    # Block 1\n",
    "    B1 = same_identity(P1,8,2)\n",
    "    B2 = valid_identity(B1,16,4)\n",
    "    B2_pool = tf.layers.max_pooling2d(B2,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P1\") # shape (178,178,16)\n",
    "    # Block 2\n",
    "    B3 = same_identity(B2_pool,32,6)\n",
    "    B4 = valid_identity(B3,64,8)\n",
    "    B4_pool = tf.layers.max_pooling2d(B4,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P2\") # shape (88,88,64)\n",
    "    # Block 3\n",
    "    B5 = same_identity(B4_pool,128,10)\n",
    "    B6 = valid_identity(B5,256,12)\n",
    "    B7 = same_identity(B6,128,14)\n",
    "    B8 = valid_identity(B7,256,16)\n",
    "    B8_pool = tf.layers.max_pooling2d(B8,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P3\") # shape (42,42,256)\n",
    "    # Block 4\n",
    "    B9 = same_identity(B8_pool,256,18)\n",
    "    B10 = valid_identity(B9,512,20)\n",
    "    B11 = same_identity(B10,256,22)\n",
    "    B12 = valid_identity(B11,512,24)\n",
    "    B12_pool = tf.layers.max_pooling2d(B12,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P4\") # shape (19,19,512)\n",
    "    # Block 5\n",
    "    B13 = same_identity(B12_pool,512,26)\n",
    "    B14 = valid_identity(B13,1024,28)\n",
    "    B15 = same_identity(B14,512,30)\n",
    "    B16 = valid_identity(B15,1024,32) # shape (15,15,1024)\n",
    "    # Final layer - no batch norm, linear activation\n",
    "    Z34 = tf.layers.conv2d(B16,filters=out,kernel_size=[1,1],strides=(1,1),padding=\"valid\",name=\"Z34\",activation=None)\n",
    "    return Z34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z shape: (3, 15, 15, 14)\n"
     ]
    }
   ],
   "source": [
    "# Testing forward prop\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X,y = get_placeholders(720,720,1,15,15,7)\n",
    "    Z34 = forward_pass(X,out=14)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    aZ = sess.run(Z34,feed_dict={X:np.random.randn(3,720,720,1),y:np.random.randn(3,15,15,7)})\n",
    "    print(\"Z shape:\", str(aZ.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the values with a specific mask applied to it\n",
    "def get_box_values(box,mask):\n",
    "    \"\"\"\n",
    "    Index:\n",
    "    0: confidence there is an object in cell, 1: mid_x, 2: mid_y, \n",
    "    3: width, 4: length, 5: prob_open_palm, 6: prob_close_palm\n",
    "    \"\"\"\n",
    "    confidence = tf.boolean_mask(box[:,:,:,0:1],mask)\n",
    "    mid_x = tf.boolean_mask(box[:,:,:,1:2],mask)\n",
    "    mid_y = tf.boolean_mask(box[:,:,:,2:3],mask)\n",
    "    width = tf.boolean_mask(box[:,:,:,3:4],mask)\n",
    "    length = tf.boolean_mask(box[:,:,:,4:5],mask)\n",
    "    prob_dog = tf.boolean_mask(box[:,:,:,5:6],mask)\n",
    "    prob_cat = tf.boolean_mask(box[:,:,:,6:7],mask)\n",
    "    box = {\"co\":confidence, \"mx\":mid_x,\"my\":mid_y,\"w\":width,\"l\":length,\"d\":prob_dog,\"c\":prob_cat}\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A component of this cost function is that it heavily penalizes negative predictions for height and weight\n",
    "# This choice was made due to the reality that it is impossible to have a negative height or width\n",
    "# This cost function functions when there is one prediction per cell\n",
    "def cost_function(Z,y,coord=5,noobj=0.5):\n",
    "    \"\"\"\n",
    "    Z - shape (?,15,15,7)\n",
    "    y - shape (?,15,15,7)\n",
    "    \"\"\"\n",
    "    c_mask_true = y[:,:,:,0:1] > 0\n",
    "    c_mask_false = y[:,:,:,0:1] < 1\n",
    "    \n",
    "    y_v = get_box_values(y,c_mask_true)\n",
    "    m_v = get_box_values(Z,c_mask_true)\n",
    "    mv_f = get_box_values(Z,c_mask_false)\n",
    "    y_f = get_box_values(y,c_mask_false)\n",
    "    \n",
    "    # penalizing width,length predictions if negative\n",
    "    m_v[\"w\"] = tf.sqrt(tf.maximum(m_v[\"w\"],0.0))\n",
    "    m_v[\"l\"] = tf.sqrt(tf.maximum(m_v[\"l\"],0.0))\n",
    "    \n",
    "    y_v[\"w\"] = tf.sqrt(y_v[\"w\"])\n",
    "    y_v[\"l\"] = tf.sqrt(y_v[\"l\"])\n",
    "    \n",
    "    # correspond to individual summations of the cost function:\n",
    "    part1 = coord * tf.reduce_sum(tf.square(y_v[\"mx\"]-m_v[\"mx\"])+tf.square(y_v[\"my\"]-m_v[\"my\"]))\n",
    "    part2 = coord * tf.reduce_sum(tf.square(y_v[\"w\"]-m_v[\"w\"])+tf.square(y_v[\"l\"]-m_v[\"l\"]))\n",
    "    part3 = tf.reduce_sum(tf.square(y_v[\"co\"]-m_v[\"co\"]))\n",
    "    part4 = noobj * tf.reduce_sum(tf.square(y_f[\"co\"]-mv_f[\"co\"]))\n",
    "    part5 = tf.reduce_sum(tf.add(tf.square(y_v[\"d\"]-m_v[\"d\"]),tf.square(y_v[\"c\"]-m_v[\"c\"])))# if obj in cell, if bounding box is highest IoU, compare class predictions\n",
    "    total_cost = part1 + part2 + part3 + part4 + part5\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7728641\n"
     ]
    }
   ],
   "source": [
    "# Testing cost function\n",
    "# predicted cost 2/ rounding error is 1.773\n",
    "ay = np.zeros((1,15,15,7))\n",
    "ay[0,0,0,:] = np.array([1,0.5,0.5,0.25,0.25,1,0]) # top left corner\n",
    "az = np.zeros((1,15,15,14))\n",
    "az[0,0,0,0:7] = np.array([0.8,0.25,0.25,0.2,0.2,0.8,0.2])\n",
    "az[0,0,1,0] = 1\n",
    "az[0,1,0,0] = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    y = tf.placeholder(tf.float32,shape=(None,15,15,7))\n",
    "    Z = tf.placeholder(tf.float32,shape=(None,15,15,14))\n",
    "    aCost = cost_function(Z,y)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    tot = sess.run(aCost,feed_dict={Z:az,y:ay})\n",
    "    print(tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates shuffled mini batches\n",
    "def random_mini_batches(X, y, mini_batch_size, seed):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    rounds = int(X.shape[0] / mini_batch_size) # Max number of minibatches\n",
    "    X_shuffle = shuffle(X, random_state=seed)\n",
    "    y_shuffle = shuffle(y, random_state=seed)\n",
    "    mini_batches = []\n",
    "    a = 0 #used to siphon off sections of X\n",
    "    b = 0 #used to siphon off sections of y\n",
    "    \n",
    "    for around in range(rounds):\n",
    "        x_mini = X_shuffle[a:a+mini_batch_size]\n",
    "        y_mini = y_shuffle[b:b+mini_batch_size]\n",
    "        mini_batch = (x_mini,y_mini)\n",
    "        mini_batches.append(mini_batch)\n",
    "        a += mini_batch_size\n",
    "        b += mini_batch_size\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building and training YOLO model\n",
    "def model(X_train,y_train,lr=0.001,minibatch_size=10,num_epochs=200,print_cost=True):\n",
    "    tf.reset_default_graph() # resetting graph\n",
    "    tf.set_random_seed(1)\n",
    "    seed=0\n",
    "    out=7 # specifying number of guesses per cell\n",
    "    costs=[]\n",
    "    x_h = X_train[0].shape[0]\n",
    "    x_w = X_train[0].shape[1]\n",
    "    x_c = X_train[0].shape[2]\n",
    "    y_h = y_train[0].shape[0]\n",
    "    y_w = y_train[0].shape[1]\n",
    "    y_c = y_train[0].shape[2]\n",
    "    m = X_train.shape[0]\n",
    "    \n",
    "    X,y = get_placeholders(x_h,x_w,x_c,y_h,y_w,y_c)\n",
    "    Z = forward_pass(X,out)\n",
    "    cost = cost_function(Z,y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        # Loading saved model\n",
    "        #saver = tf.train.import_meta_graph(\"../../structured_dl_files/models/yolo_model.ckpt.meta\")\n",
    "        #saver.restore(sess, \"../../structured_dl_files/models/yolo_model.ckpt\")\n",
    "        sess.run(init) # DONT RUN INIT IF LOADING MODEL\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            minibatch_cost = 0\n",
    "            seed += 1\n",
    "            minibatches = random_mini_batches(X_train, y_train, minibatch_size, seed)\n",
    "            \n",
    "            for minibatch in minibatches:\n",
    "                (mini_x,mini_y) = minibatch\n",
    "                _,temp_cost = sess.run([optimizer,cost], feed_dict={X:mini_x,y:mini_y})\n",
    "                minibatch_cost += temp_cost\n",
    "                print(minibatch_cost)\n",
    "                \n",
    "            costs.append(cost)\n",
    "            if print_cost and epoch % 1 == 0:\n",
    "                print(\"Cost at epoch {}: {}\".format(epoch+1,minibatch_cost))\n",
    "                \n",
    "        loc = saver.save(sess, \"../../data/dinorunner/models/yolo_model.ckpt\")\n",
    "        return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.561275482177734\n",
      "94.31476974487305\n",
      "143.95549774169922\n",
      "195.8099365234375\n",
      "231.27452850341797\n",
      "272.528751373291\n",
      "307.3873405456543\n",
      "341.2543525695801\n",
      "375.2840042114258\n",
      "402.7962417602539\n",
      "428.4767589569092\n",
      "452.70129203796387\n",
      "478.84337425231934\n",
      "500.3640308380127\n",
      "523.7244815826416\n",
      "545.8615436553955\n",
      "568.7765674591064\n",
      "591.5619564056396\n",
      "610.9421997070312\n",
      "632.4313735961914\n",
      "655.3665561676025\n",
      "679.4269065856934\n",
      "699.2887344360352\n",
      "719.8590850830078\n",
      "737.2782402038574\n",
      "758.0288848876953\n",
      "778.0089054107666\n",
      "795.3146381378174\n",
      "813.1211376190186\n",
      "833.3326091766357\n",
      "852.1805362701416\n",
      "871.7538814544678\n",
      "891.5469341278076\n",
      "911.0562381744385\n",
      "928.0097198486328\n",
      "945.5087776184082\n",
      "966.100715637207\n",
      "988.2503757476807\n",
      "1007.870080947876\n",
      "1022.9351100921631\n",
      "1043.156717300415\n",
      "1059.8920993804932\n",
      "1080.8502674102783\n",
      "1101.0978603363037\n",
      "1117.8924579620361\n",
      "1136.4077053070068\n",
      "1154.8218746185303\n",
      "Cost at epoch 1: 1154.8218746185303\n",
      "21.408294677734375\n",
      "40.89366912841797\n",
      "59.1557502746582\n",
      "76.49814414978027\n",
      "95.2033920288086\n",
      "117.93413925170898\n",
      "137.37761116027832\n",
      "159.6782741546631\n",
      "176.59213066101074\n",
      "196.12685585021973\n",
      "215.5454502105713\n",
      "235.49072647094727\n",
      "252.83019638061523\n",
      "274.5498676300049\n",
      "294.5350456237793\n",
      "312.60144424438477\n",
      "332.4255599975586\n",
      "350.8889350891113\n",
      "371.0465278625488\n",
      "387.48235511779785\n",
      "405.6476306915283\n",
      "426.8137969970703\n",
      "448.0315570831299\n",
      "465.1023426055908\n",
      "487.36193084716797\n",
      "505.1251049041748\n",
      "526.829195022583\n",
      "543.2779483795166\n",
      "562.6509017944336\n",
      "582.0809059143066\n",
      "601.9196891784668\n",
      "620.9045333862305\n",
      "639.4448394775391\n",
      "658.9704837799072\n",
      "682.0666980743408\n",
      "704.440450668335\n",
      "725.4674434661865\n",
      "744.9302997589111\n",
      "762.0635108947754\n",
      "782.3558921813965\n",
      "801.7960548400879\n",
      "819.8849601745605\n",
      "839.1589107513428\n",
      "859.6509532928467\n",
      "876.9377536773682\n",
      "895.8813343048096\n",
      "915.2819423675537\n",
      "Cost at epoch 2: 915.2819423675537\n",
      "17.65151023864746\n",
      "37.66742134094238\n",
      "55.49343681335449\n",
      "75.02362823486328\n",
      "91.87707328796387\n",
      "109.39897918701172\n",
      "127.50105667114258\n",
      "145.86346817016602\n",
      "162.93754959106445\n",
      "180.90602111816406\n",
      "199.84129333496094\n",
      "218.27959823608398\n",
      "236.6156005859375\n",
      "255.80351066589355\n",
      "276.4161891937256\n",
      "295.47423553466797\n",
      "313.0849838256836\n",
      "332.98908615112305\n",
      "352.5847682952881\n",
      "375.45379638671875\n",
      "393.38158798217773\n",
      "412.16869735717773\n",
      "429.5263328552246\n",
      "449.7061424255371\n",
      "470.37234687805176\n",
      "488.54315757751465\n",
      "506.7980556488037\n",
      "527.5600414276123\n",
      "547.1488494873047\n",
      "564.3618774414062\n",
      "585.002613067627\n",
      "603.673038482666\n",
      "623.2054138183594\n",
      "645.2964916229248\n",
      "665.2570781707764\n",
      "685.5722827911377\n",
      "705.6101226806641\n",
      "725.42600440979\n",
      "743.7778701782227\n",
      "763.460376739502\n",
      "781.0289268493652\n",
      "797.0920753479004\n",
      "816.6345596313477\n",
      "834.7412567138672\n",
      "853.7800025939941\n",
      "872.771354675293\n",
      "891.2030563354492\n",
      "Cost at epoch 3: 891.2030563354492\n",
      "18.986671447753906\n",
      "39.76821517944336\n",
      "59.5091438293457\n",
      "78.29866790771484\n",
      "98.94953155517578\n",
      "117.94049644470215\n",
      "139.34059524536133\n",
      "157.88110542297363\n",
      "180.61311149597168\n",
      "201.63859176635742\n",
      "224.02508163452148\n",
      "242.70920944213867\n",
      "259.84179878234863\n",
      "278.78301429748535\n",
      "297.6685905456543\n",
      "315.98795890808105\n",
      "333.88440132141113\n",
      "352.073205947876\n",
      "371.97612953186035\n",
      "394.43220710754395\n",
      "414.0391902923584\n",
      "435.07459449768066\n",
      "453.2073497772217\n",
      "473.41559410095215\n",
      "491.0222682952881\n",
      "510.1900463104248\n",
      "528.7182025909424\n",
      "547.5443515777588\n",
      "568.6323909759521\n",
      "585.9709358215332\n",
      "605.2836875915527\n",
      "628.3672561645508\n",
      "649.7443885803223\n",
      "667.5341758728027\n",
      "684.9320831298828\n",
      "702.5050048828125\n",
      "720.7639617919922\n",
      "740.5672035217285\n",
      "760.212272644043\n",
      "778.4606418609619\n",
      "797.8316326141357\n",
      "815.0167655944824\n",
      "835.9699058532715\n",
      "852.8199558258057\n",
      "871.3826732635498\n",
      "889.5035877227783\n",
      "910.3716926574707\n",
      "Cost at epoch 4: 910.3716926574707\n",
      "17.531965255737305\n",
      "34.42613220214844\n",
      "49.285202980041504\n",
      "69.99538516998291\n",
      "87.80253314971924\n",
      "110.16658878326416\n",
      "132.30438709259033\n",
      "151.0322732925415\n",
      "168.3367624282837\n",
      "184.81648349761963\n",
      "207.12500858306885\n",
      "229.19271183013916\n",
      "248.8500452041626\n",
      "267.5548372268677\n",
      "284.84451389312744\n",
      "303.7723150253296\n",
      "323.9971647262573\n",
      "344.5011930465698\n",
      "368.23166942596436\n",
      "386.1000967025757\n",
      "405.513445854187\n",
      "423.07383251190186\n",
      "440.67691135406494\n",
      "457.1214590072632\n",
      "474.75674533843994\n",
      "497.1958589553833\n",
      "518.0238885879517\n",
      "535.3797025680542\n",
      "572.9221239089966\n",
      "590.7722272872925\n",
      "612.7559099197388\n",
      "630.8717012405396\n",
      "651.891411781311\n",
      "671.2223062515259\n",
      "693.2542104721069\n",
      "711.6627855300903\n",
      "730.5799970626831\n",
      "747.322039604187\n",
      "766.9845151901245\n",
      "787.5478353500366\n",
      "808.802716255188\n",
      "831.5292673110962\n",
      "850.3450536727905\n",
      "866.9515371322632\n",
      "888.728663444519\n",
      "908.0188131332397\n",
      "Cost at epoch 5: 908.0188131332397\n"
     ]
    }
   ],
   "source": [
    "acosts = model(X_train,y_train,lr=0.0001,minibatch_size=8,num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n"
     ]
    }
   ],
   "source": [
    "# determining devices for system\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'CPU']\n",
    "\n",
    "a = get_available_gpus()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
