{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note - This model is actually used for this project and uses the Darknet-19 forward prop outlined in the YOLO_v2 paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO_v2 inspired model\n",
    "\n",
    "- This model takes in input images of shape (448,448,3) and produces output of shape (14,14,14). In looking at the output of my k-means clustering step in my minibatch data cleaning notebook, I decided to have 2 (1,1,7) encodings such that the model can learn the difference between the dimensions of open and closed palms.\n",
    "\n",
    "- I will be using stochastic gradient descent with adam optimization and an interatively decreasing learning rate as promoted by the YOLO_v2 model.\n",
    "\n",
    "- This model is essentially the Darknet-19 model, which I chose over the Darknet-53 resnet model strictly to decrease the time needed for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import latex\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396, 448, 448, 3)\n",
      "(396, 14, 14, 7)\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "X = np.load(\"../../data/dinorunner/images_448.npy\")\n",
    "y = np.load(\"../../data/dinorunner/encodings_448.npy\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376, 448, 448, 3)\n",
      "(376, 14, 14, 7)\n",
      "(20, 448, 448, 3)\n",
      "(20, 14, 14, 7)\n"
     ]
    }
   ],
   "source": [
    "# Creating testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder values for input X,y data\n",
    "def get_placeholders(x_h,x_w,x_c,y_h,y_w,y_c):\n",
    "    \"\"\"\n",
    "    x_h: Height for x input \n",
    "    x_w: Width for x input\n",
    "    x_c: Channels for x input\n",
    "    y_h: Height for y input\n",
    "    y_w: Width for y input\n",
    "    y_c: Channels for y input\n",
    "    \"\"\"\n",
    "    X = tf.placeholder(tf.float32, name=\"X\", shape=(None,x_h,x_w,x_c))\n",
    "    y = tf.placeholder(tf.float32, name=\"y\", shape=(None,y_h,y_w,y_c))\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (?, 448, 448, 3)\n",
      "y shape: (?, 14, 14, 7)\n"
     ]
    }
   ],
   "source": [
    "# Testing placeholders\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    X,y = get_placeholders(448,448,3,14,14,7)\n",
    "    print(\"X shape:\",X.shape)\n",
    "    print(\"y shape:\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constant layer for 2d convolution, batch norm, and activation\n",
    "def conv(the_input,layer,f,ks):\n",
    "    \"\"\"\n",
    "    the_input: the layer which will be used as input in conv layer\n",
    "    layer: specifies the layer number for naming sections of graph\n",
    "    f (filters): the number of filters to be used for conv layer\n",
    "    ks (kernel_size): kernel size for conv2d layer\n",
    "    Note - conv2d layers all use padding\n",
    "    \"\"\"\n",
    "    layer = str(layer)\n",
    "    Z = tf.layers.conv2d(the_input,filters=f,kernel_size=[ks,ks],strides=(1,1),padding=\"same\",name=\"Z\"+layer,kernel_initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    Bn = tf.layers.batch_normalization(Z,name=\"Bn\"+layer)\n",
    "    A = tf.nn.leaky_relu(Bn,alpha=0.1,name=\"A\"+layer)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the forward pass based on Darket-19\n",
    "# Note - forward pass will use leaky_relu\n",
    "def forward_pass(X):\n",
    "    input_layer = tf.reshape(X,[-1,448,448,3]) # Input shape of images\n",
    "    S1 = conv(input_layer,1,32,3)\n",
    "    P1 = tf.layers.max_pooling2d(S1,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P1\") # 224x224\n",
    "    S2 = conv(P1,2,64,3)\n",
    "    P2 = tf.layers.max_pooling2d(S2,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P2\") # 112x112\n",
    "    S3 = conv(P2,3,128,3)\n",
    "    S4 = conv(S3,4,64,1)\n",
    "    S5 = conv(S4,5,128,3)\n",
    "    P5 = tf.layers.max_pooling2d(S5,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P5\") # 56x56\n",
    "    S6 = conv(P5,6,256,3)\n",
    "    S7 = conv(S6,7,128,1)\n",
    "    S8 = conv(S7,8,256,3)\n",
    "    P8 = tf.layers.max_pooling2d(S8,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P8\") # 28x28\n",
    "    S9 = conv(P8,9,512,3)\n",
    "    S10 = conv(S9,10,256,1)\n",
    "    S11 = conv(S10,11,512,3)\n",
    "    S12 = conv(S11,12,256,1)\n",
    "    S13 = conv(S12,13,512,3)\n",
    "    P13 = tf.layers.max_pooling2d(S13,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P13\") #14x14\n",
    "    S14 = conv(P13,14,1024,3)\n",
    "    S15 = conv(S14,15,512,1)\n",
    "    S16 = conv(S15,16,1024,3)\n",
    "    S17 = conv(S16,17,512,1)\n",
    "    S18 = conv(S17,18,2014,3)\n",
    "    # Final layer - no batch norm, linear activation\n",
    "    S19 = tf.layers.conv2d(S18,filters=14,kernel_size=[1,1],strides=(1,1),padding=\"valid\",name=\"S19\",activation=None)\n",
    "    return S19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z shape: (1, 14, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "# Testing forward prop\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X,y = get_placeholders(448,448,3,14,14,7)\n",
    "    Z19 = forward_pass(X) # Computation graph\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    aZ = sess.run(Z19,feed_dict={X:np.random.randn(1,448,448,3),y:np.random.randn(1,14,14,7)})\n",
    "    print(\"Z shape:\", str(aZ.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Cost Function\n",
    "\n",
    "Using the predicted box [shape(1,1,7)] with the highest IoU score to determine the cost for a given image.\n",
    "\n",
    "Note - I deviate from the YOLO function function in that for all of the cells that don't hold the actual prediction for the bounding box, I penalize ALL of the confidence predictions (2 per cell in this case). I also penalize the prediction that is not used for the cell that holds the actual prediction. In order to compensate for this change and not greatly increase the cost from just wrong confidence scores I decrease the lambda<sub>noobj</sub> from 0.5 to 0.25. This is due to the fact that I am factoring in 2 times the previous number of confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the sum of all of the confidence scores corresponding w/ cells that don't have prediction\n",
    "def get_false_conf(Z,mask):\n",
    "    conf_1 = tf.boolean_mask(Z[:,:,:,0:1],mask)\n",
    "    conf_2 = tf.boolean_mask(Z[:,:,:,7:8],mask)\n",
    "    conf_sum = tf.add(tf.reduce_sum(conf_1),tf.reduce_sum(conf_2))\n",
    "    return conf_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the values with a specific mask applied to it\n",
    "def get_box_values(box,mask):\n",
    "    \"\"\"\n",
    "    Index:\n",
    "    0: confidence there is an object in cell, 1: mid_x, 2: mid_y, \n",
    "    3: width, 4: length, 5: prob_open_palm, 6: prob_close_palm\n",
    "    \"\"\"\n",
    "    confidence = tf.boolean_mask(box[:,:,:,0:1],mask)\n",
    "    mid_x = tf.boolean_mask(box[:,:,:,1:2],mask)\n",
    "    mid_y = tf.boolean_mask(box[:,:,:,2:3],mask)\n",
    "    width = tf.boolean_mask(box[:,:,:,3:4],mask)\n",
    "    height = tf.boolean_mask(box[:,:,:,4:5],mask)\n",
    "    prob_open = tf.boolean_mask(box[:,:,:,5:6],mask)\n",
    "    prob_closed = tf.boolean_mask(box[:,:,:,6:7],mask)\n",
    "    box = {\"co\":confidence, \"mx\":mid_x,\"my\":mid_y,\"w\":width,\"h\":height,\"d\":prob_open,\"c\":prob_closed}\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the IoU\n",
    "def get_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    box1 - coordinates (x1, y1, x2, y2)\n",
    "    box2 - coordinates (x1, y1, x2, y2)\n",
    "    \"\"\"\n",
    "    xi1 = tf.maximum(box1[\"x1\"], box2[\"x1\"])\n",
    "    yi1 = tf.maximum(box1[\"y1\"], box2[\"y1\"])\n",
    "    xi2 = tf.minimum(box1[\"x2\"], box2[\"x2\"])\n",
    "    yi2 = tf.minimum(box1[\"y2\"], box2[\"y2\"])\n",
    "    inter_area = tf.maximum((xi2 - xi1),0) * tf.maximum((yi2 - yi1),0) # no neg bounding box\n",
    "\n",
    "    box1_area = (box1[\"x2\"]-box1[\"x1\"]) * (box1[\"y2\"] - box1[\"y1\"])\n",
    "    box2_area = (box2[\"x2\"]-box2[\"x1\"]) * (box2[\"y2\"] - box2[\"y1\"])\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    iou = inter_area / union_area\n",
    "    \n",
    "    return tf.reshape(iou,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the (x1,y1),(x2,y2) coordinates for each bounding box as a dict\n",
    "def get_xy(box_v):\n",
    "    mid_x = box_v[\"mx\"]\n",
    "    mid_y = box_v[\"my\"]\n",
    "    width = box_v[\"w\"]\n",
    "    height = box_v[\"h\"]\n",
    "    width = width * 448\n",
    "    height = height * 448\n",
    "    mid_x = mid_x * 32 + 224\n",
    "    mid_y = mid_y * 32 + 224\n",
    "    \n",
    "    x1 = mid_x - (1/2*width)\n",
    "    x2 = mid_x + (1/2*width)\n",
    "    y1 = mid_y - (1/2*height)\n",
    "    y2 = mid_y + (1/2*height)\n",
    "    \n",
    "    box_xy = {\"x1\":x1,\"x2\":x2,\"y1\":y1,\"y2\":y2}\n",
    "    return box_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This returns the information associated with the bounding box prediction with the max IoU\n",
    "def get_max_iou(box1, box2, y, mask):\n",
    "    \"\"\"\n",
    "    b1_v: bounding box values associated with box1\n",
    "    b2_v: bounding box values associated with box2\n",
    "    y_v: bounding box values associated with y\n",
    "    \"\"\"\n",
    "    b1_v = get_box_values(box1,mask)\n",
    "    b2_v = get_box_values(box2,mask)\n",
    "    y_v = get_box_values(y,mask)\n",
    "    # These new coordinates will be used to get the IoU\n",
    "    b1_xy = get_xy(b1_v)\n",
    "    b2_xy = get_xy(b2_v)\n",
    "    y_xy = get_xy(y_v)\n",
    "    # Getting the Iou for each bounding box prediction\n",
    "    b1_iou = get_iou(b1_xy, y_xy)\n",
    "    b2_iou = get_iou(b2_xy, y_xy)\n",
    "    # Comparing the ious to determine which guess is the ground truth prediction\n",
    "    def b1(): return b1_v, b2_v\n",
    "    def b2(): return b2_v, b1_v\n",
    "    highest_iou_values, lowest_values = tf.cond(tf.less(b1_iou,b2_iou), b2, b1)\n",
    "    return highest_iou_values, lowest_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic gradient descent so input of shape (1,14,14,14)\n",
    "# Heavily penalizes negative predictions for height and weight\n",
    "# Bounding box prediction based on guess with the highest IoU\n",
    "def cost_function(Z,y,coord=5,noobj=0.25):\n",
    "    \"\"\"\n",
    "    Z - shape (?,14,14,14)\n",
    "    y - shape (?,14,14,7)\n",
    "    \"\"\"\n",
    "    c_mask_true = y[:,:,:,0:1] > 0 # which cell has the encoding\n",
    "    c_mask_false = y[:,:,:,0:1] < 1\n",
    "    \n",
    "    box1 = Z[:,:,:,0:7] # First guess\n",
    "    box2 = Z[:,:,:,7:14] # Second guess\n",
    "    y_v = get_box_values(y,c_mask_true) # values for y for cell with object\n",
    "    m_v,lowest_values = get_max_iou(box1,box2,y,c_mask_true) # values for highest IoU guess\n",
    "    false_conf_score = get_false_conf(Z,c_mask_false) # sum of false confidence predictions\n",
    "    false_conf_score = false_conf_score + tf.reshape(lowest_values[\"co\"],[])\n",
    "    \n",
    "    # penalizing width,length predictions if negative\n",
    "    m_v[\"w\"] = tf.sqrt(tf.maximum(m_v[\"w\"],0.0))\n",
    "    m_v[\"l\"] = tf.sqrt(tf.maximum(m_v[\"h\"],0.0))\n",
    "    \n",
    "    y_v[\"w\"] = tf.sqrt(y_v[\"w\"])\n",
    "    y_v[\"l\"] = tf.sqrt(y_v[\"h\"])\n",
    "    \n",
    "    # correspond to individual summations of the cost function:\n",
    "    part1 = coord * tf.reduce_sum(tf.square(y_v[\"mx\"]-m_v[\"mx\"])+tf.square(y_v[\"my\"]-m_v[\"my\"]))\n",
    "    part2 = coord * tf.reduce_sum(tf.square(y_v[\"w\"]-m_v[\"w\"])+tf.square(y_v[\"l\"]-m_v[\"l\"]))\n",
    "    part3 = tf.reduce_sum(tf.square(y_v[\"co\"]-m_v[\"co\"]))\n",
    "    part4 = noobj * false_conf_score\n",
    "    part5 = tf.reduce_sum(tf.add(tf.square(y_v[\"d\"]-m_v[\"d\"]),tf.square(y_v[\"c\"]-m_v[\"c\"])))\n",
    "    total_cost = part1 + part2 + part3 + part4 + part5\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6395843\n"
     ]
    }
   ],
   "source": [
    "# Testing cost function\n",
    "# predicted cost w/ rounding error is 1.6396\n",
    "ay = np.zeros((1,14,14,7))\n",
    "ay[0,0,0,:] = np.array([1,0.5,0.5,0.25,0.25,1,0]) # top left corner\n",
    "az = np.zeros((1,14,14,14))\n",
    "az[0,0,0,0:7] = np.array([0.8,0.35,0.35,0.2,0.2,0.8,0.2]) # PRED 1\n",
    "az[0,0,0,7:] = np.array([0.5,0.4,0.4,0.22,0.22,0.8,0.2]) # PRED 2\n",
    "az[0,0,1,0] = 1\n",
    "az[0,1,0,0] = 1\n",
    "az[0,1,0,7] = 1\n",
    "az[0,2,0,7] = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    y = tf.placeholder(tf.float32,shape=(None,14,14,7))\n",
    "    Z = tf.placeholder(tf.float32,shape=(None,14,14,14))\n",
    "    aCost = cost_function(Z,y)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    tot = sess.run(aCost,feed_dict={Z:az,y:ay})\n",
    "    print(tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building and training YOLO model using stochastic gradient descent\n",
    "def model(X_train,y_train,lr=0.001,num_epochs=50,print_cost=True):\n",
    "    tf.reset_default_graph() # resetting graph\n",
    "    tf.set_random_seed(1)\n",
    "    seed=0\n",
    "    costs=[]\n",
    "    x_h = X_train[0].shape[0]\n",
    "    x_w = X_train[0].shape[1]\n",
    "    x_c = X_train[0].shape[2]\n",
    "    y_h = y_train[0].shape[0]\n",
    "    y_w = y_train[0].shape[1]\n",
    "    y_c = y_train[0].shape[2]\n",
    "    m = X_train.shape[0]\n",
    "    \n",
    "    X,y = get_placeholders(x_h,x_w,x_c,y_h,y_w,y_c)\n",
    "    Z = forward_pass(X)\n",
    "    cost = cost_function(Z,y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver() # to save/load model\n",
    "    with tf.Session() as sess:\n",
    "        # Loading saved model\n",
    "        #saver = tf.train.import_meta_graph(\"../../data/dinorunner/models_stochastic/yolo_model.ckpt.meta\")\n",
    "        #saver.restore(sess, \"../../data/dinorunner/models_stochastic/yolo_model.ckpt\")\n",
    "        sess.run(init) # DON'T RUN INIT IF LOADING MODEL\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            running_cost = 0\n",
    "            # shuffling training set order each iteration\n",
    "            seed += 1\n",
    "            X_train = shuffle(X_train, random_state=seed) \n",
    "            y_train = shuffle(y_train, random_state=seed)\n",
    "            \n",
    "            for i in range(X_train.shape[0]):\n",
    "                aX = X_train[i]\n",
    "                aX.shape = (1,448,448,3)\n",
    "                aY = y_train[i]\n",
    "                aY.shape = (1,14,14,7)\n",
    "                _,temp_cost = sess.run([optimizer,cost], feed_dict={X:aX,y:aY})\n",
    "                running_cost += temp_cost\n",
    "                \n",
    "            costs.append(running_cost)\n",
    "            if print_cost and epoch % 1 == 0:\n",
    "                print(\"Cost at epoch {}: {}\".format(epoch+1,running_cost))\n",
    "                \n",
    "        loc = saver.save(sess, \"../../data/dinorunner/models_stochastic/yolo_model.ckpt\")\n",
    "        return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 448, 448, 3)\n",
      "(20, 14, 14, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 1: 2265074.9516203403\n",
      "Cost at epoch 2: 31078782.278289795\n",
      "Cost at epoch 3: 4848.251556396484\n",
      "Cost at epoch 4: 1090557.9871902466\n",
      "Cost at epoch 5: -38567.39768600464\n",
      "Cost at epoch 6: 23804281.07373047\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c15d87c39113>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macosts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprint_cost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-2098223bdc4a>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train, y_train, lr, num_epochs, print_cost)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0maY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0maY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maY\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mrunning_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtemp_cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acosts = model(X_test,y_test,lr=0.001,num_epochs=50,print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
