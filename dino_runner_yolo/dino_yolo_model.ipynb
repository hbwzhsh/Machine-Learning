{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO_v3 inspired model\n",
    "\n",
    "- This model takes in input images of shape (720,720,1) and produces output of shape (15,15,14). Given the k-means clustering analysis done in the clean data step, there are two distinct clusters of images corresponding to open and closed palm. This is due to the inherent image ratio of an open and closed palm. With these two clusters, I am building the model to recognize these two different ratios. the y output shape is (15,15,7).\n",
    "- This model is inpsired by the YOLO_v3 model and as such is comprised of residual blocks, batch normalization, and other structural elements.\n",
    "- I will be using mini-batch gradient descent with adam optimization, but will not be using an iteratively decreasing learning rate\n",
    "\n",
    "Note - given time constraints, within this current iteration of the model I am using one prediction per cell rather than 2 specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import latex\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading training data, shuffling, and creating a test subset for testing model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396, 720, 720, 1)\n",
      "(396, 15, 15, 7)\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "X = np.load(\"../../data/dinorunner/images.npy\")\n",
    "y = np.load(\"../../data/dinorunner/encodings.npy\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing image data\n",
    "X = X / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396, 720, 720, 1)\n",
      "(396, 15, 15, 7)\n"
     ]
    }
   ],
   "source": [
    "# shuffling the data \n",
    "X = shuffle(X,random_state=1)\n",
    "y = shuffle(y,random_state=1)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376, 720, 720, 1)\n",
      "(376, 15, 15, 7)\n",
      "(20, 720, 720, 1)\n",
      "(20, 15, 15, 7)\n"
     ]
    }
   ],
   "source": [
    "# Creating testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building YOLO model\n",
    "\n",
    "#### YOLO cost function:\n",
    "\n",
    "$$ \\lambda_{coord} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} 1_{ij}^{obj} \\bigg[(x_i-\\hat{x_{i}})^2 + (y_i - \\hat{y_i})^2\\bigg]$$\n",
    "$$ + \\lambda_{coord} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} 1_{ij}^{obj} \\bigg[(\\sqrt{w_i}-\\sqrt{\\hat{w_{i}}})^2 + (\\sqrt{h_i} - \\sqrt{\\hat{h_i}})^2\\bigg] $$\n",
    "$$ + \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} 1_{ij}^{obj} (c_i-\\hat{c_{i}})^2 $$\n",
    "$$ + \\lambda_{noobj} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} 1_{ij}^{noobj} (c_i-\\hat{c_{i}})^2 $$\n",
    "$$ \\sum_{i=0}^{S^{2}} 1_{i}^{obj} \\sum_{c \\in classes} (p_i(c)-\\hat{p_{i}}(c))^2 $$\n",
    "\n",
    "Note - the ground truth box in B will be the box that has the highest IoU with the true box\n",
    "\n",
    "Terms:\n",
    "- S<sup>2</sup>: the number of cells in an image (15x15)\n",
    "- B: all bounding boxes per cell (1) \n",
    "- 1<sup>obj</sup><sub>ij</sub>: denotes the bounding box predictor in cell (i,j) responsible for prediction\n",
    "- 1<sup>obj</sup><sub>ij</sub>: denotes if object appears in cell\n",
    "- C<sub>i</sub>: confidence score for whether there is an object\n",
    "- lambda<sub>coord</sub>: (5) weight factor that increases loss from bounding box predictions \n",
    "- lambda<sub>noobj</sub>: (0.5) weight factor that decreases loss from predictions for boxes that don't contain objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder values for input X,y data\n",
    "def get_placeholders(x_h,x_w,x_c,y_h,y_w,y_c):\n",
    "    \"\"\"\n",
    "    x_h: Height for x input \n",
    "    x_w: Width for x input\n",
    "    x_c: Channels for x input\n",
    "    y_h: Height for y input\n",
    "    y_w: Width for y input\n",
    "    y_c: Channels for y input\n",
    "    \"\"\"\n",
    "    X = tf.placeholder(tf.float32, name=\"X\", shape=(None,x_h,x_w,x_c))\n",
    "    y = tf.placeholder(tf.float32, name=\"y\", shape=(None,y_h,y_w,y_c))\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (?, 720, 720, 1)\n",
      "y shape: (?, 15, 15, 14)\n"
     ]
    }
   ],
   "source": [
    "# Testing placeholders\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    X,y = get_placeholders(720,720,1,15,15,14)\n",
    "    print(\"X shape:\",X.shape)\n",
    "    print(\"y shape:\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow forward prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Standard residual block which has the same input shape as output shape\n",
    "Correspond with 1. conv2d filter(1,1) \"valid\" 2. conv2d filter(3,3) \"same\"\n",
    "\"\"\"\n",
    "def same_identity(the_input,nf,sl):\n",
    "    \"\"\"\n",
    "    the_input: outut from a previous layer of conv net\n",
    "    nf: number of filters for the same_identity block\n",
    "    sl: the number of the first layer in this block\n",
    "    \"\"\"\n",
    "    shortcut = the_input # saving previous activation\n",
    "    \n",
    "    Z1 = tf.layers.conv2d(the_input,filters=nf,kernel_size=[1,1],strides=(1,1),padding=\"valid\",name=\"Z\"+str(sl),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    Bn1 = tf.layers.batch_normalization(Z1,name=\"Bn\"+str(sl))\n",
    "    A1 = tf.nn.leaky_relu(Bn1,alpha=0.1,name=\"A\"+str(sl))\n",
    "    \n",
    "    Z2 = tf.layers.conv2d(A1,filters=nf,kernel_size=[3,3],strides=(1,1),padding=\"same\",name=\"Z\"+str(sl+1),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    Bn2 = tf.layers.batch_normalization(Z2,name=\"Bn\"+str(sl+1))\n",
    "    \n",
    "    # updating old residual to new size and channel\n",
    "    shortcut_Z = tf.layers.conv2d(shortcut,filters=nf,kernel_size=[3,3],strides=(1,1),padding=\"same\",name=\"shortcut_Z\"+str(sl+1),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    shortcut_Bn = tf.layers.batch_normalization(shortcut_Z,name=\"shortcut_Bn\"+str(sl+1))\n",
    "    newZ = tf.add(Bn2,shortcut_Bn,name=\"resid_add\"+str(sl+1)) # adding old residual\n",
    "    A2 = tf.nn.leaky_relu(newZ,alpha=0.1,name=\"A\"+str(sl+1))\n",
    "    \n",
    "    return A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Standard residual block which does not have the same input shape as output shape\n",
    "Correspond with 1. conv2d filter(1,1) \"valid\" 2. conv2d filter(3,3) \"valid\"\n",
    "\"\"\"\n",
    "def valid_identity(the_input,nf,sl):\n",
    "    shortcut = the_input # saving previous activation\n",
    "    \n",
    "    Z1 = tf.layers.conv2d(the_input,filters=nf,kernel_size=[1,1],strides=(1,1),padding=\"valid\",name=\"Z\"+str(sl),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    Bn1 = tf.layers.batch_normalization(Z1,name=\"Bn\"+str(sl))\n",
    "    A1 = tf.nn.leaky_relu(Bn1,alpha=0.1,name=\"A\"+str(sl))\n",
    "    \n",
    "    Z2 = tf.layers.conv2d(A1,filters=nf,kernel_size=[3,3],strides=(1,1),padding=\"valid\",name=\"Z\"+str(sl+1),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    Bn2 = tf.layers.batch_normalization(Z2,name=\"Bn\"+str(sl+1))\n",
    "    \n",
    "    # updating old residual to new size and channel\n",
    "    shortcut_Z = tf.layers.conv2d(shortcut,filters=nf,kernel_size=[3,3],strides=(1,1),padding=\"valid\",name=\"shortcut_Z\"+str(sl+1),kernel_initializer=tf.contrib.layers.xavier_initializer(seed=5))\n",
    "    shortcut_Bn = tf.layers.batch_normalization(shortcut_Z,name=\"shortcut_Bn\"+str(sl+1))\n",
    "    newZ = tf.add(Bn2,shortcut_Bn,name=\"resid_add\"+str(sl+1)) # adding old residual\n",
    "    A2 = tf.nn.leaky_relu(newZ,alpha=0.1,name=\"A\"+str(sl+1))\n",
    "    \n",
    "    return A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Forward pass using residual blocks, batch normalization, leaky relu\n",
    "Note that these reside blocks jump over a single layer\n",
    "\"\"\"\n",
    "def forward_pass(X,out):\n",
    "    \"\"\"\n",
    "    Input image or images: X -shape(?,720,720,1)\n",
    "    out - specifies how many predictions per cell you want, multiple of 7\n",
    "    \"\"\"\n",
    "    # First layer\n",
    "    input_layer = tf.reshape(X,[-1,720,720,1])\n",
    "    Z = tf.layers.conv2d(input_layer,filters=4,kernel_size=[5,5],strides=(1,1),padding=\"same\",name=\"Z1\",kernel_initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    Bn = tf.layers.batch_normalization(Z,name=\"Bn1\")\n",
    "    A = tf.nn.leaky_relu(Bn,alpha=0.1,name=\"A1\")\n",
    "    P1 = tf.layers.max_pooling2d(A,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P1\") # shape (358,358,4)\n",
    "    # Block 1\n",
    "    B1 = same_identity(P1,8,2)\n",
    "    B2 = valid_identity(B1,16,4)\n",
    "    B2_pool = tf.layers.max_pooling2d(B2,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P1\") # shape (178,178,16)\n",
    "    # Block 2\n",
    "    B3 = same_identity(B2_pool,32,6)\n",
    "    B4 = valid_identity(B3,64,8)\n",
    "    B4_pool = tf.layers.max_pooling2d(B4,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P2\") # shape (88,88,64)\n",
    "    # Block 3\n",
    "    B5 = same_identity(B4_pool,128,10)\n",
    "    B6 = valid_identity(B5,256,12)\n",
    "    B7 = same_identity(B6,128,14)\n",
    "    B8 = valid_identity(B7,256,16)\n",
    "    B8_pool = tf.layers.max_pooling2d(B8,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P3\") # shape (42,42,256)\n",
    "    # Block 4\n",
    "    B9 = same_identity(B8_pool,256,18)\n",
    "    B10 = valid_identity(B9,512,20)\n",
    "    B11 = same_identity(B10,256,22)\n",
    "    B12 = valid_identity(B11,512,24)\n",
    "    B12_pool = tf.layers.max_pooling2d(B12,pool_size=[2,2],strides=2,padding=\"valid\",name=\"P4\") # shape (19,19,512)\n",
    "    # Block 5\n",
    "    B13 = same_identity(B12_pool,512,26)\n",
    "    B14 = valid_identity(B13,1024,28)\n",
    "    B15 = same_identity(B14,512,30)\n",
    "    B16 = valid_identity(B15,1024,32) # shape (15,15,1024)\n",
    "    # Final layer - no batch norm, linear activation\n",
    "    Z34 = tf.layers.conv2d(B16,filters=out,kernel_size=[1,1],strides=(1,1),padding=\"valid\",name=\"Z34\",activation=None)\n",
    "    return Z34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z shape: (3, 15, 15, 14)\n"
     ]
    }
   ],
   "source": [
    "# Testing forward prop\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X,y = get_placeholders(720,720,1,15,15,7)\n",
    "    Z34 = forward_pass(X,out=14)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    aZ = sess.run(Z34,feed_dict={X:np.random.randn(3,720,720,1),y:np.random.randn(3,15,15,7)})\n",
    "    print(\"Z shape:\", str(aZ.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the values with a specific mask applied to it\n",
    "def get_box_values(box,mask):\n",
    "    \"\"\"\n",
    "    Index:\n",
    "    0: confidence there is an object in cell, 1: mid_x, 2: mid_y, \n",
    "    3: width, 4: length, 5: prob_open_palm, 6: prob_close_palm\n",
    "    \"\"\"\n",
    "    confidence = tf.boolean_mask(box[:,:,:,0:1],mask)\n",
    "    mid_x = tf.boolean_mask(box[:,:,:,1:2],mask)\n",
    "    mid_y = tf.boolean_mask(box[:,:,:,2:3],mask)\n",
    "    width = tf.boolean_mask(box[:,:,:,3:4],mask)\n",
    "    length = tf.boolean_mask(box[:,:,:,4:5],mask)\n",
    "    prob_dog = tf.boolean_mask(box[:,:,:,5:6],mask)\n",
    "    prob_cat = tf.boolean_mask(box[:,:,:,6:7],mask)\n",
    "    box = {\"co\":confidence, \"mx\":mid_x,\"my\":mid_y,\"w\":width,\"l\":length,\"d\":prob_dog,\"c\":prob_cat}\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A component of this cost function is that it heavily penalizes negative predictions for height and weight\n",
    "# This choice was made due to the reality that it is impossible to have a negative height or width\n",
    "# This cost function functions when there is one prediction per cell\n",
    "def cost_function(Z,y,coord=5,noobj=0.5):\n",
    "    \"\"\"\n",
    "    Z - shape (?,15,15,7)\n",
    "    y - shape (?,15,15,7)\n",
    "    \"\"\"\n",
    "    c_mask_true = y[:,:,:,0:1] > 0\n",
    "    c_mask_false = y[:,:,:,0:1] < 1\n",
    "    \n",
    "    y_v = get_box_values(y,c_mask_true)\n",
    "    m_v = get_box_values(Z,c_mask_true)\n",
    "    mv_f = get_box_values(Z,c_mask_false)\n",
    "    y_f = get_box_values(y,c_mask_false)\n",
    "    \n",
    "    # penalizing width,length predictions if negative\n",
    "    m_v[\"w\"] = tf.sqrt(tf.maximum(m_v[\"w\"],0.0))\n",
    "    m_v[\"l\"] = tf.sqrt(tf.maximum(m_v[\"l\"],0.0))\n",
    "    \n",
    "    y_v[\"w\"] = tf.sqrt(y_v[\"w\"])\n",
    "    y_v[\"l\"] = tf.sqrt(y_v[\"l\"])\n",
    "    \n",
    "    # correspond to individual summations of the cost function:\n",
    "    part1 = coord * tf.reduce_sum(tf.square(y_v[\"mx\"]-m_v[\"mx\"])+tf.square(y_v[\"my\"]-m_v[\"my\"]))\n",
    "    part2 = coord * tf.reduce_sum(tf.square(y_v[\"w\"]-m_v[\"w\"])+tf.square(y_v[\"l\"]-m_v[\"l\"]))\n",
    "    part3 = tf.reduce_sum(tf.square(y_v[\"co\"]-m_v[\"co\"]))\n",
    "    part4 = noobj * tf.reduce_sum(tf.square(y_f[\"co\"]-mv_f[\"co\"]))\n",
    "    part5 = tf.reduce_sum(tf.add(tf.square(y_v[\"d\"]-m_v[\"d\"]),tf.square(y_v[\"c\"]-m_v[\"c\"])))# if obj in cell, if bounding box is highest IoU, compare class predictions\n",
    "    total_cost = part1 + part2 + part3 + part4 + part5\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7728641\n"
     ]
    }
   ],
   "source": [
    "# Testing cost function\n",
    "# predicted cost 2/ rounding error is 1.773\n",
    "ay = np.zeros((1,15,15,7))\n",
    "ay[0,0,0,:] = np.array([1,0.5,0.5,0.25,0.25,1,0]) # top left corner\n",
    "az = np.zeros((1,15,15,14))\n",
    "az[0,0,0,0:7] = np.array([0.8,0.25,0.25,0.2,0.2,0.8,0.2])\n",
    "az[0,0,1,0] = 1\n",
    "az[0,1,0,0] = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    y = tf.placeholder(tf.float32,shape=(None,15,15,7))\n",
    "    Z = tf.placeholder(tf.float32,shape=(None,15,15,14))\n",
    "    aCost = cost_function(Z,y)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    tot = sess.run(aCost,feed_dict={Z:az,y:ay})\n",
    "    print(tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates shuffled mini batches\n",
    "def random_mini_batches(X, y, mini_batch_size, seed):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    rounds = int(X.shape[0] / mini_batch_size) # Max number of minibatches\n",
    "    X_shuffle = shuffle(X, random_state=seed)\n",
    "    y_shuffle = shuffle(y, random_state=seed)\n",
    "    mini_batches = []\n",
    "    a = 0 #used to siphon off sections of X\n",
    "    b = 0 #used to siphon off sections of y\n",
    "    \n",
    "    for around in range(rounds):\n",
    "        x_mini = X_shuffle[a:a+mini_batch_size]\n",
    "        y_mini = y_shuffle[b:b+mini_batch_size]\n",
    "        mini_batch = (x_mini,y_mini)\n",
    "        mini_batches.append(mini_batch)\n",
    "        a += mini_batch_size\n",
    "        b += mini_batch_size\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building and training YOLO model\n",
    "def model(X_train,y_train,lr=0.001,minibatch_size=10,num_epochs=200,print_cost=True):\n",
    "    tf.reset_default_graph() # resetting graph\n",
    "    tf.set_random_seed(1)\n",
    "    seed=0\n",
    "    out=7 # specifying number of guesses per cell\n",
    "    costs=[]\n",
    "    x_h = X_train[0].shape[0]\n",
    "    x_w = X_train[0].shape[1]\n",
    "    x_c = X_train[0].shape[2]\n",
    "    y_h = y_train[0].shape[0]\n",
    "    y_w = y_train[0].shape[1]\n",
    "    y_c = y_train[0].shape[2]\n",
    "    m = X_train.shape[0]\n",
    "    \n",
    "    X,y = get_placeholders(x_h,x_w,x_c,y_h,y_w,y_c)\n",
    "    Z = forward_pass(X,out)\n",
    "    cost = cost_function(Z,y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        # Loading saved model\n",
    "        #saver = tf.train.import_meta_graph(\"../../structured_dl_files/models/yolo_model.ckpt.meta\")\n",
    "        #saver.restore(sess, \"../../structured_dl_files/models/yolo_model.ckpt\")\n",
    "        sess.run(init) # DONT RUN INIT IF LOADING MODEL\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            minibatch_cost = 0\n",
    "            seed += 1\n",
    "            minibatches = random_mini_batches(X_train, y_train, minibatch_size, seed)\n",
    "            \n",
    "            for minibatch in minibatches:\n",
    "                (mini_x,mini_y) = minibatch\n",
    "                _,temp_cost = sess.run([optimizer,cost], feed_dict={X:mini_x,y:mini_y})\n",
    "                minibatch_cost += temp_cost\n",
    "                print(minibatch_cost)\n",
    "                \n",
    "            costs.append(cost)\n",
    "            if print_cost and epoch % 1 == 0:\n",
    "                print(\"Cost at epoch {}: {}\".format(epoch+1,minibatch_cost))\n",
    "                \n",
    "        loc = saver.save(sess, \"../../data/dinorunner/models/yolo_model.ckpt\")\n",
    "        return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.04043197631836\n",
      "60.93362045288086\n",
      "84.93712043762207\n",
      "117.32965660095215\n",
      "Cost at epoch 1: 117.32965660095215\n",
      "23.53525733947754\n",
      "43.37421417236328\n",
      "64.17424392700195\n",
      "81.34169387817383\n",
      "Cost at epoch 2: 81.34169387817383\n",
      "16.932031631469727\n",
      "30.4316463470459\n",
      "46.926259994506836\n",
      "59.77484130859375\n",
      "Cost at epoch 3: 59.77484130859375\n",
      "11.745929718017578\n",
      "27.09506607055664\n",
      "39.28932189941406\n",
      "53.55013465881348\n",
      "Cost at epoch 4: 53.55013465881348\n",
      "13.176772117614746\n",
      "27.113338470458984\n",
      "38.51589298248291\n",
      "50.039286613464355\n",
      "Cost at epoch 5: 50.039286613464355\n",
      "11.43337631225586\n",
      "24.58958339691162\n",
      "36.926283836364746\n",
      "47.992445945739746\n",
      "Cost at epoch 6: 47.992445945739746\n",
      "13.770750045776367\n",
      "24.437564849853516\n",
      "36.474928855895996\n",
      "48.693490982055664\n",
      "Cost at epoch 7: 48.693490982055664\n",
      "12.233196258544922\n",
      "24.312040328979492\n",
      "36.146156311035156\n",
      "47.638129234313965\n",
      "Cost at epoch 8: 47.638129234313965\n",
      "11.155258178710938\n",
      "21.258485794067383\n",
      "33.95774745941162\n"
     ]
    }
   ],
   "source": [
    "acosts = model(X_test,y_test,lr=0.0001,minibatch_size=5,num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.04043197631836\n",
      "97.62533187866211\n",
      "121.35266876220703\n",
      "139.71456909179688\n",
      "Cost at epoch 1: 139.71456909179688\n",
      "64.25847625732422\n",
      "88.9889907836914\n",
      "111.2067756652832\n",
      "129.00164604187012\n",
      "Cost at epoch 2: 129.00164604187012\n",
      "72.91453552246094\n",
      "122.355224609375\n",
      "146.93384552001953\n",
      "175.11642456054688\n",
      "Cost at epoch 3: 175.11642456054688\n",
      "18.090496063232422\n",
      "42.812294006347656\n",
      "59.6079158782959\n",
      "74.99165344238281\n",
      "Cost at epoch 4: 74.99165344238281\n",
      "13.9739351272583\n",
      "29.14718723297119\n",
      "41.92204475402832\n",
      "54.14919662475586\n",
      "Cost at epoch 5: 54.14919662475586\n",
      "12.313671112060547\n",
      "26.495532989501953\n",
      "38.37582492828369\n",
      "49.04843235015869\n",
      "Cost at epoch 6: 49.04843235015869\n",
      "14.183731079101562\n",
      "26.07059097290039\n",
      "37.67594623565674\n",
      "49.1345739364624\n",
      "Cost at epoch 7: 49.1345739364624\n",
      "10.993560791015625\n",
      "25.532718658447266\n",
      "37.626444816589355\n",
      "48.94414806365967\n",
      "Cost at epoch 8: 48.94414806365967\n",
      "10.959125518798828\n",
      "21.616361618041992\n",
      "34.697364807128906\n",
      "46.39060401916504\n",
      "Cost at epoch 9: 46.39060401916504\n",
      "11.069358825683594\n",
      "22.42675018310547\n",
      "35.3493127822876\n",
      "45.480430603027344\n",
      "Cost at epoch 10: 45.480430603027344\n",
      "12.192719459533691\n",
      "22.80732250213623\n",
      "34.86848163604736\n",
      "46.27212047576904\n",
      "Cost at epoch 11: 46.27212047576904\n",
      "10.629472732543945\n",
      "22.406432151794434\n",
      "33.280043601989746\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4d6eea7677d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macosts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0003\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-08f7088eeb76>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train, y_train, lr, minibatch_size, num_epochs, print_cost)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminibatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mmini_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmini_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmini_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmini_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0mminibatch_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtemp_cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acosts = model(X_test,y_test,lr=0.0003,minibatch_size=5,num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n"
     ]
    }
   ],
   "source": [
    "# determining devices for system\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'CPU']\n",
    "\n",
    "a = get_available_gpus()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
