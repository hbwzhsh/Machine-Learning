{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN language model to predict plausible dinosaur names\n",
    "\n",
    "The decision to do a language model based on dinosaur games was inspired by a project I had when working on a deep learning course offered by Deeplearning.ai. The data used within this notebook was found [here](\"https://github.com/brunoklein99/deep-learning-notes\"). This model is built to learn to correctly predict y<sup>t</sup> = x<sup>t+1</sup>, essentially being able to take in a sequence of characters and predicting the most plausible next character. For this model I will be using sets of three input characters to predict the next input character. I chose to ignore whether \\n was was the final character in a set of three characters for the sake of brevity. I chose to simply ignore training examples in which \"\\n\" was the first character as that should never come up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import latex\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(10)\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'c', 'h', 'e', 'n', 'o', 's', 'u', 'r', '\\n', 'd', 'y', 'x', 'b', 'l', 'i', 't', 'p', 'v', 'm', 'g', 'f', 'j', 'k', 'w', 'z', 'q']\n",
      "no chars: 27\n"
     ]
    }
   ],
   "source": [
    "# Reading in data - creating dictionaries specifying how to encode data (into characters)\n",
    "chars = []\n",
    "all_names = []\n",
    "with open(\"../../data/dino_names/names.txt\") as names:\n",
    "    lines = names.readlines()\n",
    "    for line in lines:\n",
    "        line = line.lower()\n",
    "        for char in line:\n",
    "            if char not in chars:\n",
    "                chars.append(char)\n",
    "        all_names.append(line) # \\n included\n",
    "                \n",
    "print(chars)\n",
    "print(\"no chars:\",len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "max char len: 27\n",
      "min char len: 4\n"
     ]
    }
   ],
   "source": [
    "# Analysis of the names set\n",
    "print(len(all_names))\n",
    "print(\"max char len:\", len(max(all_names,key=len)))\n",
    "print(\"min char len:\", len(min(all_names,key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating encoder and decoder\n",
    "i = 1\n",
    "encoder = {\"\\n\":0} # char to id, set \\n to be 0\n",
    "decoder = {0:\"\\n\"} # id to char\n",
    "\n",
    "for char in chars:\n",
    "    if char != \"\\n\":\n",
    "        encoder[char] = i\n",
    "        decoder[i] = char\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns one hot encoding for a particular character\n",
    "def get_one_hot_encoding(char):\n",
    "    char_enc = encoder[char]\n",
    "    hot_vec = np.zeros((27,1)) # vocab_size = 27\n",
    "    hot_vec[char_enc] = 1\n",
    "    hot_vec = hot_vec.T # shape (1,27)\n",
    "    return hot_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the int representation for a set of characters, i.e. \"abc\"\n",
    "def get_character_encoding(chars):\n",
    "    ret_enc = []\n",
    "    m = len(chars)\n",
    "    for c in chars:\n",
    "        c_int = encoder[c] # int representation\n",
    "        ret_enc.append(c_int)\n",
    "        \n",
    "    ret_enc = np.array(ret_enc)\n",
    "    ret_enc.shape = (1,m) # shape (num_input, 1) for x variable\n",
    "    return ret_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list of ((1,3),(1,27)) pairs corresponding with ((x_train_set),(y_output))\n",
    "def get_training_examples(lis_names,seed):\n",
    "    shuf_names = shuffle(lis_names,random_state=seed) # shuffling data\n",
    "    all_names = \"\".join(shuf_names) # create one long string of names\n",
    "    training_set = []\n",
    "    i = 3\n",
    "    while (i < len(all_names)):\n",
    "        x_temp = get_character_encoding(all_names[i-3:i])\n",
    "        y_temp = get_one_hot_encoding(all_names[i]) # x^<t+1>\n",
    "        if x_temp[0] != \"\\n\":\n",
    "            training_set.append((x_temp,y_temp)) # only append if example doesnt start with \\n\n",
    "        i += 3\n",
    "    \n",
    "    return training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6636\n",
      "x shape: (1, 3)\n",
      "y shape: (1, 27)\n"
     ]
    }
   ],
   "source": [
    "# Getting initial training set / testing func.\n",
    "training_set = get_training_examples(all_names,seed=0)\n",
    "print(len(training_set))\n",
    "print(\"x shape:\", training_set[100][0].shape)\n",
    "print(\"y shape:\", training_set[100][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting one word only, so y shape = (1,num_chars)\n",
    "# num_input = 3 representing\n",
    "def get_placeholders(num_input=3):\n",
    "    x = tf.placeholder(tf.float32, shape=[1, num_input], name='X')\n",
    "    y = tf.placeholder(tf.float32, shape=[1, 27], name='Y')\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializer the weights user for lstm, 512 is the no. hidden units per lstm cell\n",
    "def get_weight():\n",
    "    return tf.get_variable(\"w\",dtype=tf.float32,shape=[512,27],initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializer for the bias terms, initializing to zeros\n",
    "def get_bias():\n",
    "    return tf.get_variable(\"b\",dtype=tf.float32,shape=[27],initializer=tf.keras.initializers.Zeros())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the rnn block with lstm cells\n",
    "# w: weight term, b: bias term\n",
    "def rnn_cell(the_input,w,b,n_input=3):\n",
    "    the_input = tf.split(the_input, n_input, axis=1) # create subtensor for each char\n",
    "    rnn_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=512,activation=tf.nn.tanh) # 512 hidden units per cell\n",
    "    outputs, curr_state = tf.nn.static_rnn(rnn_cell,inputs=the_input,dtype=tf.float32) # output for each input\n",
    "    out = tf.matmul(outputs[-1],w) + b # get the logit for last y_hat\n",
    "    return out # returns logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a character input x^<t>, this returns the argmax of y^<t>\n",
    "# this also returns the hidden state for c,a to be used in the next rnn cell\n",
    "def sample(the_input,w,b,past_state,n_input=1):\n",
    "    \"\"\"\n",
    "    past_state: lstm state from previous seq., 0 if the first cell (past_state=None)\n",
    "    \"\"\"\n",
    "    the_input = tf.split(the_input, n_input, axis=1) # create subtensor for each char\n",
    "    rnn_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=512,activation=tf.nn.tanh)\n",
    "    \n",
    "    if past_state == None: # first lstm cell, initial state = zeros\n",
    "        outputs, curr_state = tf.nn.static_rnn(rnn_cell,inputs=the_input,dtype=tf.float32)\n",
    "    else: # not first lstm cell, use past_state input\n",
    "        outputs, curr_state = tf.nn.static_rnn(rnn_cell,inputs=the_input,initial_state=past_state,dtype=tf.float32)\n",
    "        \n",
    "    out = tf.matmul(outputs[-1],w) + b # get the logit for last y_hat\n",
    "    sft_out = tf.nn.softmax(out) # shape (1,27)\n",
    "    out_char_num = tf.argmax(sft_out,axis=-1)\n",
    "    return tf.reshape(out_char_num,()),curr_state # char and hidden state for a,c outputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting initial values for weight and bias terms\n",
    "tf.reset_default_graph()\n",
    "b = get_bias()\n",
    "w = get_weight()\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    ab,aw = sess.run([b,w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qithftkjbhcoxy\n"
     ]
    }
   ],
   "source": [
    "# Testing the ability to get samples from the trained rnn architecture\n",
    "out_char = \"\"\n",
    "ax = np.array([20]) # first input letter\n",
    "ax.shape = (1,1)\n",
    "past_state = None\n",
    "tf.reset_default_graph()\n",
    "b = tf.placeholder(tf.float32, shape=[27], name='b')\n",
    "w = tf.placeholder(tf.float32, shape=[512,27], name='w')\n",
    "x = tf.placeholder(tf.float32, shape=[1,1], name='x')\n",
    "rnn_state_output = sample(x,w,b,past_state)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    while out_char != \"\\n\":\n",
    "        sess.run(init)\n",
    "        out_char_num,past_state = sess.run(rnn_state_output,feed_dict={x:ax,b:ab,w:aw})\n",
    "        out_char = decoder[out_char_num]\n",
    "        out_char_num = np.array([int(out_char_num)])\n",
    "        out_char_num.shape = (1,1)\n",
    "        ax = out_char_num\n",
    "        print(out_char,end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross entropy loss because we are comparing the output of y^<t> and x^<t+1>\n",
    "def cost_function(logits,y):\n",
    "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2692502\n"
     ]
    }
   ],
   "source": [
    "# Testing rnn cells and cost function\n",
    "tf.reset_default_graph()\n",
    "b = get_bias()\n",
    "w = get_weight()\n",
    "x,y = get_placeholders()\n",
    "rnn_output = rnn_cell(x,w,b)\n",
    "cost = cost_function(rnn_output,y)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    acost = sess.run(cost,feed_dict={x:training_set[100][0],y:training_set[100][1]})\n",
    "    print(acost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for language model\n",
    "def model(names_set,lr=0.01,num_epochs=100):\n",
    "    tf.reset_default_graph() # resetting graph\n",
    "    tf.set_random_seed(1)\n",
    "    seed=0\n",
    "    costs=[]\n",
    "    \n",
    "    b = get_bias() # Preinitializing the weight and bias terms\n",
    "    w = get_weight()\n",
    "    x,y = get_placeholders()\n",
    "    logits = rnn_cell(x,w,b)\n",
    "    cost = cost_function(logits,y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver() # to save/load model\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "            running_cost = 0\n",
    "            seed += 1\n",
    "            training_set = get_training_examples(names_set,seed)\n",
    "            for aset in training_set:\n",
    "                (ax,ay) = aset\n",
    "                _,temp_cost = sess.run([optimizer,cost], feed_dict={x:ax,y:ay})\n",
    "                running_cost += temp_cost\n",
    "                \n",
    "            costs.append(running_cost)\n",
    "            if epoch % 1 == 0: # printing costs\n",
    "                print(\"Cost at epoch {}: {}\".format(epoch+1,running_cost))\n",
    "            \n",
    "            if epoch % 10 == 0: # printing out valid names\n",
    "                \n",
    "                \n",
    "        aab,aaw = sess.run([b,w])\n",
    "                \n",
    "        loc = saver.save(sess, \"../../data/dino_names/model/language_model.ckpt\")\n",
    "        return costs,aab,aaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 1: 335.4938665628433\n",
      "Cost at epoch 2: 295.19920670986176\n",
      "Cost at epoch 3: 262.02488708496094\n"
     ]
    }
   ],
   "source": [
    "acosts,aab,aaw = model(all_names,lr=0.01,num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving parameters\n",
    "np.save(\"../../data/dino_names/terms/bias.npy\",aab)\n",
    "np.save(\"../../data/dino_names/terms/weight.npy\",aaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "    # prints out samples of dinosaur names\n",
    "    if epoch % 1 == 0:\n",
    "        for i in range(5):\n",
    "            output = \"\"\n",
    "            first_char = np.random.randint(1,27)\n",
    "            first_char = np.array([first_char])\n",
    "            first_char.shape = (1,1)\n",
    "            prev_o = sess.run(rnn_cell(the_input,w,b,1),feed_dict={the_input = first_char})\n",
    "            \n",
    "            while output != \"\\n\":\n",
    "                \n",
    "                output = sess.run(rnn_cell(the_input,w,b,1), feed_dict={the_input = output})\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
