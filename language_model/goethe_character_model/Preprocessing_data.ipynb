{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project aimed at creating a character language model based on Goethe's Wilhelm Meister\n",
    "\n",
    "The model will take variable length input, with the belief that it would be beneficial for the model to learn different ranges of dependencies. The max length of the character input will be 30 characters, with the minimum being 5 characters. The length of the actual input will be 30, with zero-padding being used along with a tf dynamic rnn to make this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import latex\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(10)\n",
    "from random import randint\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to see all the unique characters and their respective frequencies\n",
    "char_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../data/goethe/wilhelm_meister.txt\") as file:\n",
    "    for line in file.readlines():\n",
    "        for char in line: # accessing all chars, including \\n\n",
    "            if char not in char_dict:\n",
    "                char_dict[char] = 1\n",
    "            else:\n",
    "                char_dict[char] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['B', 'o', 'k', ' ', 'I', 'C', 'h', 'a', 'p', 't', 'e', 'r', '\\n', 'T', 'H', 'E', 'P', 'L', 'A', 'Y', 'w', 's', 'l', 'i', 'n', 'b', 'g', 'u', ':', 'd', 'm', 'c', ',', 'f', '.', 'S', 'M', 'y', '’', 'N', 'v', ';', '-', 'x', 'O', 'q', '!', '“', 'W', '?', '”', 'j', 'z', 'V', 'J', 'G', 'D', 'F', '‘', 'K', '—', 'U', 'Q', 'R', 'X', '̈', '́', '(', ')', '6', 'æ', '7', '̂', '̀', '8', 'Z', '/', 'œ', '\"'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unqiue chars in the novel: 66\n"
     ]
    }
   ],
   "source": [
    "# Making an encoder and decoder for all of the characters in the novel\n",
    "keys = ['B', 'o', 'k', ' ', 'I', 'C', 'h', 'a', 'p', 't', 'e', 'r', '\\n', \n",
    "        'T', 'H', 'E', 'P', 'L', 'A', 'Y', 'w', 's', 'l', 'i', 'n', 'b', \n",
    "        'g', 'u', ':', 'd', 'm', 'c', ',', 'f', '.', 'S', 'M', 'y', '’', \n",
    "        'N', 'v', ';', '-', 'x', 'O', 'q', '!', '“', 'W', '?', '”', 'j', \n",
    "        'z', 'V', 'J', 'G', 'D', 'F', '‘', 'K', '—', 'U', 'Q', 'R', 'X', 'Z']\n",
    "\n",
    "encoder = {}\n",
    "decoder = {}\n",
    "key_no = 1 # the int representing a key\n",
    "for key in keys:\n",
    "    encoder[key] = key_no\n",
    "    decoder[key_no] = key\n",
    "    key_no += 1\n",
    "    \n",
    "print(\"Number of unqiue chars in the novel:\",len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chars: 1202452\n"
     ]
    }
   ],
   "source": [
    "# grabbing all of the characters in a simple list \n",
    "# this was done after the initial file open b/c not all chars will be used based on frequency\n",
    "char_list = []\n",
    "\n",
    "with open(\"../../../data/goethe/wilhelm_meister.txt\") as file:\n",
    "    for line in file.readlines():\n",
    "        for char in line: # accessing all chars, including \\n\n",
    "            if encoder.get(char) != None: # valid character\n",
    "                char_list.append(char)\n",
    "                \n",
    "print(\"Total number of chars:\",len(char_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns one hot encoding for a particular character\n",
    "def get_one_hot_encoding(char):\n",
    "    char_enc = encoder[char]\n",
    "    hot_vec = np.zeros((67,1)) # vocab_size = 66 (indexed at 1 so need 67 spots)\n",
    "    hot_vec[char_enc] = 1\n",
    "    hot_vec = hot_vec.T # shape (1,67)\n",
    "    return hot_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loops and creates data until it reaches the end of all of the characters\n",
    "def create_data(char_list):\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    lis_len = len(char_list)\n",
    "    char_i = 0 # keeps track of which char from char_list input we are on\n",
    "    while True:\n",
    "        input_len = randint(5,30)\n",
    "        if (char_i + input_len + 1) > lis_len: # basically reached end of chars\n",
    "            break\n",
    "\n",
    "        ax = np.zeros((30,67))\n",
    "        ay = get_one_hot_encoding(char_list[input_len]) # getting the y label\n",
    "        for offset in range(0,input_len):\n",
    "            achar = get_one_hot_encoding(char_list[char_i + offset])\n",
    "            ax[offset] = achar\n",
    "        \n",
    "        ax.shape = (1,30,67)\n",
    "        ay.shape = (1,67)\n",
    "        X_data.append(ax)\n",
    "        y_data.append(ay)\n",
    "        char_i += 2\n",
    "    \n",
    "    return X_data,y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data,y_data = create_data(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601213\n"
     ]
    }
   ],
   "source": [
    "print(len(X_data)) # the number of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601213, 1, 30, 67)\n",
      "(601213, 1, 67)\n"
     ]
    }
   ],
   "source": [
    "# reshape the data into a numpy array\n",
    "X_arr = np.array(X_data)\n",
    "y_arr = np.array(y_data)\n",
    "print(X_arr.shape)\n",
    "print(y_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "np.save(\"../../../data/goethe/X_arr.npy\",X_arr)\n",
    "np.save(\"../../../data/goethe/y_arr.npy\",y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
